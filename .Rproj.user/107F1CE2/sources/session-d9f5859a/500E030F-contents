---
title: "nature_of_data"
format: html
---

## What Do We Mean by “Data”?

### Formal and historical definitions

::: callout-note
“facts or information used usually to calculate, analyze, or plan something” Merriam-Webster (2016) “quantities, principles or facts given, known, or admitted, by which to find things or results unknown” Merriam-Webster (1828)
:::

### Data as collections, not facts

-   \[Contrast facts vs. measurements vs. structured datasets\]

-   \[Highlight why these distinctions matter for analysis\]

-   \[Use simple examples (e.g., organism traits) to distinguish statements from distributions\]

-   \[Discuss why variability is the object of study, not noise\]

### Raw data as a data lake

-   \[Describe raw field and lab data as unstructured or semi-structured collections\]
-   \[Discuss messiness, redundancy, error, and incompleteness often entwined with ecology\]
-   \[Explain why raw data are rarely analysis-ready\]

## Types of Data You Already Work With

### Field and lab data

-   \[Describe observational, experimental, and opportunistic data\]
-   \[Discuss common sources of bias and error\]

### Processed and derived data

-   \[Explain how raw measurements become summaries, indices, or features\]
-   \[Discuss loss of information and gain of interpretability\]

### Multivariate and high-dimensional data

-   \[Describe movement data, behavior time series, trait matrices\]
-   \[Emphasize correlation, dependence, and structure\]

### Spatial, social, and interaction data

-   \[Outline spatial distributions, networks, and interaction matrices\]
-   \[Highlight challenges unique to these data types\]

## From Data to Knowledge

### The conventional scientific workflow

-   \[Outline the standard sequence: question → hypothesis → test → inference\]
-   \[Acknowledge how this is taught vs. how it is practiced\]

### Alternative, data-first workflows

-   \[Introduce exploratory-first or iterative approaches\]
-   \[Discuss when questions emerge from data rather than precede them\]

### Data reuse and synthesis

-   \[Explain how analyzed data feed meta-analyses and new questions\]
-   \[Discuss reproducibility and re-analysis\] \## Welcome!





------------------------------------------------------------------------

------------------------------------------------------------------------

## What Do We Mean by “Data”?

You were asked to come into this course with data. But what *are* data?

Here are two definitions, separated by roughly 200 years:

-   **Modern definition (2016):**\
    *Facts or information used to calculate, analyze, or plan something.*

-   **Older definition:**\
    *Quantities, principles, or facts given or admitted by which to find things or results unknown.*

I strongly prefer the older definition.

Data are **facts we have observed**.\
Information is what we *derive* from them through modeling.

We do not collect information.\
We collect data and *create* or *extract*information. 

------------------------------------------------------------------------

## From Raw Observations to Inference

Consider a historical field notebook page from Alexander Skutch, working in Panama in the 1950s.\
It contains: - sketches\
- behavioral observations\
- weather notes\
- natural history context

This is what we might now call a **data lake**—many data types mixed together.

Your job as a quantitative scientist is to: - recognize what kinds of data you have\
- understand their boundaries\
- decide how to model them appropriately

------------------------------------------------------------------------

## Examples of the Data You May Have

Many of you are working with **multivariate behavioral data**: - accelerometer data\
- movement paths\
- velocity, direction, distance over time

These often include **exogenous data**: - terrain\
- habitat structure\
- climate

Others of you may be using **remote sensing or external datasets**: - climate products\
- LiDAR\
- long-term monitoring databases

Combining data across sources introduces serious challenges of **scale**, **resolution**, and **non-independence**.

::: callout-warning
Scale mismatches are one of the most common—and most damaging—sources of analytical error.
:::

You may also be working with: - social network data\
- derived metrics (centrality, entropy, redundancy)\
- spatial distributions\
- literature-derived datasets for meta-analysis

These data types are powerful—and very easy to analyze incorrectly if boundaries and assumptions are ignored.

------------------------------------------------------------------------

## A Critical Warning About Visualization

Raw data visualization is **not inference**.

I am deeply skeptical of many data visualizations used in popular media. They often: - show raw data only\
- include no modeling\
- imply causation or explanation

As scientists, we would never get away with that.

Inference comes from **models**, not plots alone.

------------------------------------------------------------------------

## A Short Reflection Exercise

::: {.callout-note collapse="true" title="Pause and reflect (3 minutes)"}
Think about your dataset and answer these questions for yourself:

1.  **Where did the data come from?**
    -   Your own observations?\
    -   A public database?\
    -   Remote sensing?
2.  **What are the data types?**
    -   Numeric, categorical, character?\
    -   Images, audio, spatial data?
3.  **What are the major challenges?**
    -   Sample size limitations\
    -   Spatial or temporal non-independence\
    -   Biases introduced during collection or processing\
:::

This reflection will make the next lectures much more productive.
