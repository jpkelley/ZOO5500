---
title: "Generalized Linear Models for Count Data"
subtitle: "Day 3 — Video 2"
author: "Patrick Kelley"
format:
  html:
    toc: true
    toc-depth: 3
editor: visual
---

## Overview

Welcome back to Day 3. This is the second video on generalized linear models (GLMs), focusing specifically on **models for non-normal data**. In this lecture, we work through **count data** as a concrete case study to build intuition about model choice, diagnostics, prediction, and interpretation.

These ideas will be reinforced through hands-on practice in class.

---

## Poisson GLMs for Count Data

Count data are extremely common in ecological surveys and field studies. Whenever your response variable is a count (e.g., number of individuals, detections, or events), the **Poisson distribution** is often the natural starting point.

A defining property of the Poisson distribution is:

> **The mean equals the variance.**

Formally,

$$
\mathbb{E}(Y) = \mathrm{Var}(Y)
$$

This means the distribution is fully specified by a single parameter (the mean). Other distributions often require additional parameters to describe dispersion.

---

## Link Functions for the Poisson Distribution

Several link functions are available for Poisson GLMs:

- Identity  
- Square root  
- **Log (default and most commonly used)**

The **log link** is generally preferred because it ensures that fitted values are **strictly positive**, which is required for count data.

With a log link:

- The linear predictor is on the log scale
- The inverse link is the exponential function
- Coefficients are interpreted multiplicatively after back-transformation

If $\eta$ is the linear predictor, then the mean response is:

$$
\mu = \exp(\eta)
$$

Back-transforming model output is critical for interpretation and prediction.

---

## Assumptions of the Poisson GLM

For a Poisson GLM to be appropriate, the response must satisfy:

$$
\mathrm{Var}(Y) \approx \mathbb{E}(Y)
$$

To evaluate this assumption, we calculate an **overdispersion parameter**. Ideally, this value should be close to **1**.

- Dispersion $> 1$: **Overdispersion**
- Dispersion $< 1$: **Underdispersion**

In practice, overdispersion is far more common than underdispersion.

---

## Calculating the Dispersion Statistic

If dispersion is not reported automatically, it can be calculated as:

$$
\hat{c} = \frac{\sum r_i^2}{n - p}
$$

where:

- $r_i$ are Pearson residuals  
- $n$ is the number of observations  
- $p$ is the number of estimated parameters (including the intercept)

For mixed models, defining $p$ becomes more complicated because the effective sample size lies between the number of observations and the number of random-effect levels.

---

## When Overdispersion Is a Symptom

Before assuming overdispersion is the primary issue, consider other common causes:

1. Model misspecification (missing predictors)
2. Influential observations or outliers
3. Missing interaction terms
4. Predictors on inappropriate scales
5. Unmodeled nonlinear relationships
6. Zero inflation
7. Unaccounted dependency structure

A standard GLM assumes **independent observations** with no spatial, temporal, or hierarchical structure.

---

## Strategies for Handling Overdispersion

### Quasi-Poisson Models

Quasi-Poisson models adjust standard errors to account for overdispersion while leaving the mean structure unchanged. This is a technical fix and can work in some cases, but it is not always ideal.

### Negative Binomial Models (Preferred)

The negative binomial distribution includes two parameters:

- Mean
- Dispersion parameter

This allows the variance to exceed the mean:

$$
\mathrm{Var}(Y) = \mu + \alpha \mu^2
$$

where $\alpha$ controls overdispersion. This makes negative binomial GLMs a robust choice for overdispersed count data.

---

## Why Distribution Choice Matters

At large mean values, a Poisson distribution can visually resemble a normal distribution. However, the underlying assumptions remain different.

If variance is mischaracterized:

- Standard errors will be incorrect
- Confidence intervals will be misleading
- p-values may be invalid

A good decision workflow is:

1. Is the response discrete or continuous?
2. What are the bounds of the data?
3. Does variance increase with the mean?

---

## Example Dataset: Fish Abundance and Water Depth

We now consider a dataset designed to address the question:

> Has the relationship between water depth and total fish abundance changed over time?

Before modeling, we:

- Inspect variable structure
- Remove a spatial outlier (for teaching purposes)
- Rescale depth for interpretability

Always examine your data first, but avoid making inferential claims from exploratory plots alone.

---

## Ordinary Least Squares as a Baseline

We begin with a Gaussian linear model:

$$
\text{Total abundance} \sim \text{Mean depth}
$$

The model reports a strong effect of depth. However, residual diagnostics reveal major violations:

- Heteroskedasticity
- Skewed residuals
- Non-normality
- Influential observations

Q–Q plots confirm these violations. This model is not appropriate for count data.

---

## Residuals in GLMs

In GLMs, raw residuals (observed minus fitted) are not useful. Instead, use:

- **Pearson residuals**
- **Deviance residuals**

These should be plotted against:

- Fitted values
- Each predictor
- Time
- Space

Residuals should show no systematic structure across any variable.

---

## Fitting a Poisson GLM

We refit the model using a Poisson GLM with a log link:

$$
\log(\mu_i) = \beta_0 + \beta_1 \text{Depth}_i
$$

The model explains approximately 43% of the deviance:

$$
R^2_{\text{pseudo}} = \frac{D_\text{null} - D_\text{residual}}{D_\text{null}}
$$

However, diagnostics reveal extreme overdispersion.

---

## Explicit Overdispersion Diagnosis

Using Pearson residuals, we compute:

$$
\hat{c} \approx 115
$$

This indicates severe overdispersion and confirms that the Poisson model is mis-specified.

---

## Model Refinement Attempts

We explore several refinements:

- Cook’s distance reveals many influential points
- Adding sampling period as a covariate improves fit marginally
- Adding an offset for sampling effort worsens dispersion

Each step provides diagnostic information but does not resolve the issue.

---

## Negative Binomial GLM

We refit the same model using a **negative binomial GLM**:

$$
\log(\mu_i) = \beta_0 + \beta_1 \text{Depth}_i + \beta_2 \text{Period}_i
$$

This dramatically improves the model:

- Dispersion $\approx 1$
- Residuals stabilize
- Cook’s distance values drop
- AIC strongly favors the negative binomial model

---

## Interpreting the Final Model

The depth–abundance relationship is similar across periods. However, claims about similarity require explicit comparison between:

- Additive models
- Interaction models

Only after comparing these models can we infer whether relationships truly differ.

---

## Prediction and Back-Transformation

When predicting from GLMs:

- Always use `type = "link"`
- Request standard errors
- Compute confidence intervals on the link scale
- Back-transform using the inverse link

For a log link, predictions are back-transformed as:

$$
\hat{\mu} = \exp(\hat{\eta})
$$

Confidence intervals are:

$$
\exp(\hat{\eta} \pm 1.96 \cdot \text{SE})
$$

This produces asymmetric intervals appropriate for count data.

---

## A Cautionary Example

In a published study of reproductive success, predictions were plotted on the **link scale**, leading to biologically impossible negative values. The model itself was correct—the error occurred during prediction and visualization.

This mistake is common and avoidable.

---

## Key Take-Home Messages

- Use Poisson GLMs for count data whenever appropriate
- Always check for zero inflation and overdispersion
- Prefer negative binomial models when overdispersion is present
- Never extrapolate beyond observed data ranges
- Default to `type = "link"` when predicting
- Always back-transform predictions and confidence intervals

---

## Wrap-Up

This concludes Day 3. In Day 4, we will continue building on these ideas and extend them to more complex modeling frameworks.
