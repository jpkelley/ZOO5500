<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>9&nbsp; AI Prompting for Analysis – Quantitative Analysis of (Messy) Field Data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/project_scoping.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-f2c6d6e2b784ddc5de38779acc06f37d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/ai_prompting.html">Part ∅: AI preparation</a></li><li class="breadcrumb-item"><a href="../chapters/ai_prompting.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">AI Prompting for Analysis</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../graphics/jackalope_graphics/analytical_jackalope.png" alt="" class="sidebar-logo light-content py-0 d-lg-inline d-none">
      <img src="../graphics/jackalope_graphics/analytical_jackalope.png" alt="" class="sidebar-logo dark-content py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Quantitative Analysis of (Messy) Field Data</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Course Overview</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Information</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/course_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/syllabus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Syllabus</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/calendar_sp26.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Course calendar</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/ai_policy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">GenAI Use Guidelines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/preparing_yourself.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Preparing Yourself</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/assignment_grades.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Assignments &amp; Grades</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/project_scoping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Project Scoping</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part ∅: AI preparation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/ai_prompting.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">AI Prompting for Analysis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Part I: Chaos to Columns</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Part II: Columns to Curves</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Part III: Curves to Meaning</span></span>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview"><span class="header-section-number">9.1</span> Overview</a>
  <ul class="collapse">
  <li><a href="#what-are-large-language-models-e.g.-chatgpt-gemini-claude" id="toc-what-are-large-language-models-e.g.-chatgpt-gemini-claude" class="nav-link" data-scroll-target="#what-are-large-language-models-e.g.-chatgpt-gemini-claude"><span class="header-section-number">9.1.1</span> What are Large Language Models (e.g.&nbsp;ChatGPT, Gemini, Claude)</a></li>
  <li><a href="#what-are-prompts" id="toc-what-are-prompts" class="nav-link" data-scroll-target="#what-are-prompts"><span class="header-section-number">9.1.2</span> What are prompts?</a></li>
  </ul></li>
  <li><a href="#engineering-successful-prompts" id="toc-engineering-successful-prompts" class="nav-link" data-scroll-target="#engineering-successful-prompts"><span class="header-section-number">9.2</span> Engineering Successful Prompts</a>
  <ul class="collapse">
  <li><a href="#the-iterative-prompting-loop" id="toc-the-iterative-prompting-loop" class="nav-link" data-scroll-target="#the-iterative-prompting-loop"><span class="header-section-number">9.2.1</span> The iterative prompting loop</a></li>
  <li><a href="#why-good-prompting-matters-and-why-you-should-verify-outputs" id="toc-why-good-prompting-matters-and-why-you-should-verify-outputs" class="nav-link" data-scroll-target="#why-good-prompting-matters-and-why-you-should-verify-outputs"><span class="header-section-number">9.2.2</span> Why good prompting matters (and why you should <em>verify</em> outputs)</a></li>
  <li><a href="#actions-for-writing-strong-prompts" id="toc-actions-for-writing-strong-prompts" class="nav-link" data-scroll-target="#actions-for-writing-strong-prompts"><span class="header-section-number">9.2.3</span> Actions for writing strong prompts</a></li>
  <li><a href="#trace-a-framework-for-writing-strong-prompts" id="toc-trace-a-framework-for-writing-strong-prompts" class="nav-link" data-scroll-target="#trace-a-framework-for-writing-strong-prompts"><span class="header-section-number">9.2.4</span> TRACE: a framework for writing strong prompts</a></li>
  </ul></li>
  <li><a href="#evaluating-llm-output" id="toc-evaluating-llm-output" class="nav-link" data-scroll-target="#evaluating-llm-output"><span class="header-section-number">9.3</span> Evaluating LLM Output</a>
  <ul class="collapse">
  <li><a href="#the-rubric-prompt-synergy" id="toc-the-rubric-prompt-synergy" class="nav-link" data-scroll-target="#the-rubric-prompt-synergy"><span class="header-section-number">9.3.1</span> The Rubric-Prompt Synergy</a></li>
  <li><a href="#rubric-criteria" id="toc-rubric-criteria" class="nav-link" data-scroll-target="#rubric-criteria"><span class="header-section-number">9.3.2</span> Rubric criteria</a></li>
  <li><a href="#quantifying-model-drift-another-way-to-put-rubrics-to-work" id="toc-quantifying-model-drift-another-way-to-put-rubrics-to-work" class="nav-link" data-scroll-target="#quantifying-model-drift-another-way-to-put-rubrics-to-work"><span class="header-section-number">9.3.3</span> Quantifying Model Drift: Another way to put rubrics to work</a></li>
  </ul></li>
  <li><a href="#synthesis-examples-of-improving-prompts" id="toc-synthesis-examples-of-improving-prompts" class="nav-link" data-scroll-target="#synthesis-examples-of-improving-prompts"><span class="header-section-number">9.4</span> Synthesis: Examples of improving prompts</a>
  <ul class="collapse">
  <li><a href="#example-1-debugging-r-code" id="toc-example-1-debugging-r-code" class="nav-link" data-scroll-target="#example-1-debugging-r-code"><span class="header-section-number">9.4.1</span> Example 1: Debugging R code</a></li>
  <li><a href="#example-2-choosing-a-model-strategy-polished-but-incomplete" id="toc-example-2-choosing-a-model-strategy-polished-but-incomplete" class="nav-link" data-scroll-target="#example-2-choosing-a-model-strategy-polished-but-incomplete"><span class="header-section-number">9.4.2</span> Example 2: Choosing a model strategy <em>(polished but incomplete)</em></a></li>
  <li><a href="#example-3-interpreting-a-model-result" id="toc-example-3-interpreting-a-model-result" class="nav-link" data-scroll-target="#example-3-interpreting-a-model-result"><span class="header-section-number">9.4.3</span> Example 3: Interpreting a model result</a></li>
  <li><a href="#example-4-checking-model-assumptions-polished-but-incomplete" id="toc-example-4-checking-model-assumptions-polished-but-incomplete" class="nav-link" data-scroll-target="#example-4-checking-model-assumptions-polished-but-incomplete"><span class="header-section-number">9.4.4</span> Example 4: Checking model assumptions <em>(polished but incomplete)</em></a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/ai_prompting.html">Part ∅: AI preparation</a></li><li class="breadcrumb-item"><a href="../chapters/ai_prompting.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">AI Prompting for Analysis</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">AI Prompting for Analysis</span></h1>
<p class="subtitle lead">Writing useful prompts quickly</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This page covers the basics of Large Language Models (LLM), the fundamentals of good prompt engineering and design, and the specifics of how to interact with the JackalopeGPT, the custom GPT for this course.</p>
<section id="overview" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">9.1</span> Overview</h2>
<section id="what-are-large-language-models-e.g.-chatgpt-gemini-claude" class="level3" data-number="9.1.1">
<h3 data-number="9.1.1" class="anchored" data-anchor-id="what-are-large-language-models-e.g.-chatgpt-gemini-claude"><span class="header-section-number">9.1.1</span> What are Large Language Models (e.g.&nbsp;ChatGPT, Gemini, Claude)</h3>
<p><a href="https://chatgpt.com/g/g-696966777a948191858541cd7986057e-jackalopegpt">JackalopeGPT</a> is a customized GPT assistant tailored specifically for this course using <a href="chatgpt.com">OpenAI’s ChatGPT</a>, a Large Language Model (LLM). Large Language Models (LLMs) like ChatGPT are advanced generative artifical intelligence systems trained on absolutely massive collections of text, enabling them to answer complex questions, summarize information, write in particular styles, and interact using natural language. Large Language Models are trained in two distinct steps that intentionally put humans in the loop:</p>
<ul>
<li><strong>Supervised fine-tuning (SFT)</strong> teaches the model <em>what to say</em> by training on human-written input–output examples.</li>
<li><strong>Reinforcement learning from human feedback (RLHF)</strong> teaches the model <em>how to say it</em> by rewarding outputs people judge as better (clearer, safer, more helpful, etc.).</li>
</ul>
<p>The key takeaway is very practical for our purposes in this course: these models are optimized for <em>interaction</em> (between the user and LLM). The trade-off is that they are not necessarily built for accuracy. Model responses to users’ prompts (see Section 8.1.2) can sound amazingly confident and authoritative even when their information is grossly incorrect.</p>
</section>
<section id="what-are-prompts" class="level3" data-number="9.1.2">
<h3 data-number="9.1.2" class="anchored" data-anchor-id="what-are-prompts"><span class="header-section-number">9.1.2</span> What are prompts?</h3>
<p>As stated above, you begin each interaction with an LLM using a prompt. A <strong>prompt</strong> is simply your input to the trained model; it is your question or request. There are two broad classes of prompts that are operationally differentiated by their purpose:</p>
<ul>
<li><strong>Evaluative prompts:</strong> Models that <em>produce</em> content (e.g., text, code, summaries, or ideas).</li>
<li><strong>Generative prompts:</strong> Models that assess or critique ingested data.</li>
</ul>
<p>In this course, your goal for JackalopeGPT is not to “get an answer,” so we primarily use evaluative prompts. This prompting type keeps you in control of important scientific decisions and constrains the model’s role to that of a friendly reviewer or sounding board (rather than an autonomous data scientist).</p>
<div class="callout callout-style-default callout-note callout-titled" title="Good prompt engineering takes practice">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Good prompt engineering takes practice
</div>
</div>
<div class="callout-body-container callout-body">
<p>Please note that it may take a bit of practice to concisely write prompts that contain all of this information <em>and</em> yield high-quality responses, but this is a good framework to get you started.</p>
</div>
</div>
</section>
</section>
<section id="engineering-successful-prompts" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="engineering-successful-prompts"><span class="header-section-number">9.2</span> Engineering Successful Prompts</h2>
<section id="the-iterative-prompting-loop" class="level3" data-number="9.2.1">
<h3 data-number="9.2.1" class="anchored" data-anchor-id="the-iterative-prompting-loop"><span class="header-section-number">9.2.1</span> The iterative prompting loop</h3>
<p>Successful prompting is usually iterative, involving the following basic steps:</p>
<ol type="1">
<li><strong>State expectations clearly.</strong> Your goal is to produce an output you can evaluate.</li>
<li><strong>Evaluate the response using a documented rubric.</strong> You should always have an implicit (or explicit) <strong>rubric</strong> in mind: a short set of criteria that defines what a <em>good</em> response should contain.</li>
<li><strong>Revise the prompt to reduce ambiguity and increase verifiability.</strong> Use the rubric to improve the prompt by clarifying the task/topic/context, adding constraints, and requiring formal checks so the response is easier to evaluate.</li>
<li><strong>Repeat (briefly, yet thoughtfully).</strong> until the output is actionable.</li>
</ol>
</section>
<section id="why-good-prompting-matters-and-why-you-should-verify-outputs" class="level3" data-number="9.2.2">
<h3 data-number="9.2.2" class="anchored" data-anchor-id="why-good-prompting-matters-and-why-you-should-verify-outputs"><span class="header-section-number">9.2.2</span> Why good prompting matters (and why you should <em>verify</em> outputs)</h3>
<p>Large Language Models can be extremely helpful, but they are not a scientific authority, and its responses are not “timeless.” That is, the quality of the responses depends heavily on what you ask and when you ask it (given what information has been recently folded into the LLM training).</p>
</section>
<section id="actions-for-writing-strong-prompts" class="level3" data-number="9.2.3">
<h3 data-number="9.2.3" class="anchored" data-anchor-id="actions-for-writing-strong-prompts"><span class="header-section-number">9.2.3</span> Actions for writing strong prompts</h3>
<ul>
<li><strong>Leverage your expertise:</strong> Use your biological knowledge to define what matters: structure of your study design, sources of bias (detectability of individuals), confounding variables, scale, or non-independence.</li>
<li><strong>Be challenging and specific.</strong> Remove the escape routes. Provide the response type, design, predictors, and what you want back (models, diagnostics, interpretation template).</li>
<li><strong>Use explicit constraints:</strong> Tell it <em>how</em> to answer (format, scope, evidence requirements), not just <em>what</em> to answer.</li>
<li>Force juggling: Require it to handle multiple issues at once (e.g., zero inflation + nesting + spatial clustering).</li>
<li><strong>Keep it realistic:</strong> Ask for defensible inference, not magic. Explicitly ask it to flag overreach.</li>
<li><strong>Make prompts reusable:</strong> Favor principles and reasoning over tool/version-specific instructions (unless needed).</li>
<li><strong>Make prompts unambiguous and evaluable:</strong> Avoid “this/that/the above” references that only make sense outside the current chat.</li>
<li><strong>Avoid broad prompts; make outputs verifiable.</strong> Interaction GPTs love to spread their wings when given some wiggle room.</li>
<li><strong>Write original prompts.</strong> Writing original prompts grounds the model in how you think about a scientific question. The model can help refine language or suggest options, but it should not invent the prompt’s goals.</li>
</ul>
<hr>
</section>
<section id="trace-a-framework-for-writing-strong-prompts" class="level3" data-number="9.2.4">
<h3 data-number="9.2.4" class="anchored" data-anchor-id="trace-a-framework-for-writing-strong-prompts"><span class="header-section-number">9.2.4</span> TRACE: a framework for writing strong prompts</h3>
<p>Use <strong>TRACE</strong> as a memory hook (technically, a <em>acronymic mnemonic</em>) for what to include in high-quality, repeatable prompts:</p>
<ul>
<li><strong>T (Task/Topic, aka Context):</strong> What problem are you working on? What’s the data/design?</li>
<li><strong>R (Role):</strong> What kind of helper should JackalopeGPT be?</li>
<li><strong>A (Audience):</strong> What level should it explain to?</li>
<li><strong>C (Criteria):</strong> What must a good answer include?</li>
<li><strong>E (Exclusions):</strong> What should it avoid? What is out-of-scope?</li>
</ul>
<p>Here is a more detailed description. The bracketed, italicized components indicate places where you enter your original prompt components. Examples are given in the Description column.</p>
<div class="course-info" data-tbl-colwidths="[10, 14, 78]">
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 14%">
<col style="width: 77%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Letter</strong></th>
<th><strong>Component</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>T</strong></td>
<td><strong>Task / Topic</strong></td>
<td>I am working on: <em>[system + response + sampling design + sample sizes]. Known issues: [zeros / detectability / spatial clustering / non-independence / confounding]</em>. <br> <br> Example: I have repeated point counts at 30 sites (4 visits per site). The response variable is bird counts per visit. Predictors include canopy density, wind, and observer. I expect detection of individuals to decline as a function of canopy density and wind.</td>
</tr>
<tr class="even">
<td><strong>R</strong></td>
<td><strong>Role</strong></td>
<td>Act as a <em>[R tutor / methods advisor / model debugger]</em>. <br> <br> Example: Act as an ecology methods advisor and R tutor.</td>
</tr>
<tr class="odd">
<td><strong>A</strong></td>
<td><strong>Audience</strong></td>
<td>Explain to a <em>[specified knowledge level]</em>. <br> <br> Example: Explain to a 1st–2nd year ecology graduate student with basic statistics knowledge, who has 5–6 months’ experience working with Generalized Linear Models (GLMs) in R.</td>
</tr>
<tr class="even">
<td><strong>C</strong></td>
<td><strong>Criteria</strong></td>
<td>A good answer must include: <em>[(1) restate the design, (2) assumptions, (3) 2–3 candidate approaches, (4) diagnostics and checks, (5) interpretation limits and what would change the recommendation.]</em> <br> <br> Example: Propose two scientifically defensible modeling approaches. For each, state assumptions, specify the model structure (in words or formula), list at least two scientifically defensible model diagnostics, and explain what result would be misleading if detection bias is not accounted for.</td>
</tr>
<tr class="odd">
<td><strong>E</strong></td>
<td><strong>Exclusions</strong></td>
<td>Do not: <em>[write my full assignment / invent data / claim causality / skip assumptions / provide code if concepts only were requested]</em>. <br> <br> Example: Do not claim causal effects. Do not invent data. Do not write end-to-end analysis code. If information is missing, list what is needed rather than guessing.</td>
</tr>
</tbody>
</table>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="TRACE templates for your convenience">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>TRACE templates for your convenience
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><a href="https://docs.google.com/spreadsheets/d/15rYGpF3wQqdCU-ZavdV6zQuujT26Vlanh2aU4xunxMg/edit?usp=sharing"><strong>Google Sheet template</strong></a> (Read-only; you can copy and paste)</p>
<p><a href="https://docs.google.com/document/d/1np-z958LhN47FsOl5IAVZatDeBqq7_xHqdKz1VgnpFo/edit?usp=sharing"><strong>Google Doc template</strong></a> (Read-only; you can copy and paste)</p>
</div>
</div>
</div>
</section>
</section>
<section id="evaluating-llm-output" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="evaluating-llm-output"><span class="header-section-number">9.3</span> Evaluating LLM Output</h2>
<section id="the-rubric-prompt-synergy" class="level3" data-number="9.3.1">
<h3 data-number="9.3.1" class="anchored" data-anchor-id="the-rubric-prompt-synergy"><span class="header-section-number">9.3.1</span> The Rubric-Prompt Synergy</h3>
<p>A rubric is your short checklist for what a complete and accurate response must include. Do not skip it or underestimate its utility: LLMs can sound confident while being downright wrong and incomplete. A good rubric –derived from your own expertise– is how you keep yourself in control of the LLM’s behavior.</p>
<p>Think of your <strong>prompt</strong> as a cake recipe and the <strong>rubric</strong> as the taste test. (I am already thinking this analogy isn’t worth its salt.) The cake might look finished and ready to bring to the party, but the rubric if what tells you whether the cake is actually edible. In other words, you and your rubric must:</p>
<ul>
<li><strong>NOT</strong> ask <em>“Is this answer impressive and sounds smart?”</em><br>
</li>
<li>Definitely ask <em>“Is this answer complete, appropriately constrained, and testable or verifiable?”</em></li>
</ul>
</section>
<section id="rubric-criteria" class="level3" data-number="9.3.2">
<h3 data-number="9.3.2" class="anchored" data-anchor-id="rubric-criteria"><span class="header-section-number">9.3.2</span> Rubric criteria</h3>
<p>After developing and running a conceptually good prompt, you can be satisfied that a response is worth using if it satisfies the following criteria:</p>
<ul>
<li>Gets the problem right<br>
</li>
<li>States its assumptions<br>
</li>
<li>Explains its reasoning<br>
</li>
<li>Shows how to check itself<br>
</li>
<li>Knows where it could be wrong</li>
</ul>
<p>If any one of these is missing, revise the <strong>prompt</strong> before revising your analysis. To see details about each of the above criteria, click on the green box below to expand.</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="Detailed criteria for assessing LLM responses">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Detailed criteria for assessing LLM responses
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="does-it-get-the-problem-right" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="does-it-get-the-problem-right">Does it get the problem right?</h3>
<ul>
<li>Check whether the response correctly restates your system, data, and task.</li>
<li>Look for invented details or a mischaracterized study design.</li>
<li>If this fails, stop and revise the <strong>prompt</strong> (not your interpretation).</li>
</ul>
<hr>
</section>
<section id="does-it-state-its-assumptions" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="does-it-state-its-assumptions">Does it state its assumptions?</h3>
<ul>
<li>Identify whether assumptions are explicit (e.g., independence, sampling, detection, distributional form, causal limits).</li>
<li>Missing or vague assumptions make recommendations hard to evaluate.</li>
<li>Treat missing assumptions as a <strong>prompt failure</strong>, not a model error.</li>
</ul>
<hr>
</section>
<section id="does-it-explain-its-reasoning" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="does-it-explain-its-reasoning">Does it explain its reasoning?</h3>
<ul>
<li>Look for a clear, step-by-step chain from <strong>design → model → inference</strong>.</li>
<li>Explanations should justify <em>why</em> recommendations follow from the setup.</li>
<li>Without step-by-step reasoning, we cannot evaluate conclusions.</li>
</ul>
<hr>
</section>
<section id="is-it-verifiable" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="is-it-verifiable">Is it verifiable?</h3>
<ul>
<li>The response should include at least one diagnostic, stress test, or sensitivity check (which we will discuss later in the course)</li>
<li>It should explain how the recommendation could fail or mislead.</li>
<li>Advice without checks is not trustworthy.</li>
</ul>
<hr>
</section>
<section id="does-it-know-where-it-could-be-wrong" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="does-it-know-where-it-could-be-wrong">Does it know where it could be wrong?</h3>
<ul>
<li>Check for limits: what cannot be concluded, what would be overreach, what remains uncertain.</li>
<li>Look for acknowledgment of uncertainty.</li>
<li>Overconfidence is a severe red flag.</li>
</ul>
</section>
</div>
</div>
</div>
</section>
<section id="quantifying-model-drift-another-way-to-put-rubrics-to-work" class="level3" data-number="9.3.3">
<h3 data-number="9.3.3" class="anchored" data-anchor-id="quantifying-model-drift-another-way-to-put-rubrics-to-work"><span class="header-section-number">9.3.3</span> Quantifying Model Drift: Another way to put rubrics to work</h3>
<p>Large Language Models are updated and adjusted over time. That means the same prompt can yield different answers across weeks or months—sometimes subtly, sometimes dramatically. To stay scientifically grounded, you need a habit of <strong>validation</strong>, a way to detect when the LLM’s behavior has changed and when outputs should no longer be trusted. Consider the following scenario. Imagine you weigh your study subjects on a scale every morning. A lab jackanape recalibrates the scale every few weeks without telling you. After discovering that this has occurred, would you trust that the measurements are directly comparable across time? However, if your lab protocol included a daily measurement of a standardized set of weights, you could determine exactly when recalibrations were back, and, what’s even better, you could adjust your measurements accordingly. Science would be saved!</p>
<div class="green-box" data-collapse="true">
<p><strong>A practical –and easy– way to assess “model drift” in your own work</strong></p>
<ul>
<li>Keep 3–5 <strong>benchmark prompts</strong> you reuse all semester (e.g., <em>“fit a GLMM with random intercept for site, explain assumptions, propose diagnostics”</em>). Ideally, you should document and store these as metadata, so that the phrase(s) can always be connected to a project and also be easily accessed.</li>
<li>Re-run the same benchmark prompt occasionally (at a predefined interval or whenever you begin a new interaction or project). Save (copy/paste) the <strong>prompt + output</strong> into your AI Interaction Log.</li>
<li>Examine the output for changes in:
<ul>
<li>whether it correctly restates the design,</li>
<li>whether it flags assumptions and/or constraints,</li>
<li>whether it proposes diagnostics that are scientifically defensible,</li>
<li>whether it starts inventing details or over-claiming.</li>
<li><em>[other criteria that you can think of?]</em></li>
</ul></li>
</ul>
</div>
</section>
</section>
<section id="synthesis-examples-of-improving-prompts" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="synthesis-examples-of-improving-prompts"><span class="header-section-number">9.4</span> Synthesis: Examples of improving prompts</h2>
<p><strong>Instructions to students:</strong> Read the excessively broad-scope prompt first. Pause and think: * <em>What information is missing (hint: use the TRACE framework)?</em> * <em>What verbiage could be added to fill most or all of those missing components?</em> Then expand the box to see a stronger version (based in the TRACE framework)</p>
<p><strong>Rubric tag key (TRACE):</strong><br>
- <strong>[T]</strong> Task/Topic context missing or underspecified<br>
- <strong>[R]</strong> Role missing<br>
- <strong>[A]</strong> Audience missing<br>
- <strong>[C]</strong> Criteria missing (what a “good” answer must include)<br>
- <strong>[E]</strong> Exclusions missing (scope/safeguards)</p>
<hr>
<section id="example-1-debugging-r-code" class="level3" data-number="9.4.1">
<h3 data-number="9.4.1" class="anchored" data-anchor-id="example-1-debugging-r-code"><span class="header-section-number">9.4.1</span> Example 1: Debugging R code</h3>
<blockquote class="blockquote">
<p>“My model isn’t working. Help.”</p>
</blockquote>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="Click to reveal a stronger prompt (TRACE)">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Click to reveal a stronger prompt (TRACE)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Missing tags:</strong> [T] [R] [A] [C] [E]<br>
<strong>Rubric tags addressed:</strong> [T] [R] [A] [C] [E]</p>
<blockquote class="blockquote">
<p>“Act as an <strong>R debugger</strong>. I’m a <strong>beginner–intermediate R user</strong>. I’m fitting a <strong>GLMM for counts</strong> with a <strong>random intercept for site</strong>. Here is my code and the <strong>exact error message</strong>: [paste].<br>
A good answer must:<br>
(1) identify the likely cause,<br>
(2) show the minimal fix,<br>
(3) explain why it failed, and<br>
(4) suggest one diagnostic check.<br>
Do not rewrite my entire analysis—just fix the error and explain.”</p>
</blockquote>
</div>
</div>
</div>
<hr>
</section>
<section id="example-2-choosing-a-model-strategy-polished-but-incomplete" class="level3" data-number="9.4.2">
<h3 data-number="9.4.2" class="anchored" data-anchor-id="example-2-choosing-a-model-strategy-polished-but-incomplete"><span class="header-section-number">9.4.2</span> Example 2: Choosing a model strategy <em>(polished but incomplete)</em></h3>
<blockquote class="blockquote">
<p>“I have ecological count data collected over multiple sites and years, and I want to choose an appropriate statistical model that accounts for structure in the data. Can you recommend a suitable modeling approach and explain why?”</p>
</blockquote>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="Click to reveal a stronger prompt (TRACE)">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Click to reveal a stronger prompt (TRACE)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Missing tags:</strong> [C] [E]<br>
<strong>Rubric tags addressed:</strong> [T] [R] [A] [C] [E]</p>
<blockquote class="blockquote">
<p>“Act as an <strong>ecology methods advisor</strong>. I have <strong>count data with many zeros</strong>; samples <strong>nested</strong> in plots within sites; <strong>repeated measures</strong> over time.<br>
Compare <strong>2–3 modeling strategies</strong> (e.g., <strong>negative binomial GLMM vs zero-inflated vs hurdle</strong>), state <strong>assumptions</strong>, and give <strong>diagnostics that would falsify each</strong>.<br>
Do not claim causality; focus on defensible inference.”</p>
</blockquote>
</div>
</div>
</div>
<p><em>Why this works pedagogically:</em><br>
The initial prompt sounds careful and scientific, but it fails to <strong>bound the answer</strong> and <strong>require checks</strong>, inviting a vague or overbroad response.</p>
<hr>
</section>
<section id="example-3-interpreting-a-model-result" class="level3" data-number="9.4.3">
<h3 data-number="9.4.3" class="anchored" data-anchor-id="example-3-interpreting-a-model-result"><span class="header-section-number">9.4.3</span> Example 3: Interpreting a model result</h3>
<blockquote class="blockquote">
<p>“How do I interpret this coefficient?”</p>
</blockquote>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="Click to reveal a stronger prompt (TRACE)">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Click to reveal a stronger prompt (TRACE)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Missing tags:</strong> [T] [R] [A] [C] [E]<br>
<strong>Rubric tags addressed:</strong> [T] [R] [A] [C] [E]</p>
<blockquote class="blockquote">
<p>“Act as a <strong>statistical interpreter for ecology graduate students</strong>. I’m fitting a <strong>negative binomial GLMM</strong> for bird counts with <strong>canopy cover</strong> as a predictor and <strong>site as a random effect</strong>.<br>
Explain how to interpret the canopy coefficient on the <strong>link scale</strong> and <strong>response scale</strong>, state the <strong>assumptions</strong> required for this interpretation, and describe <strong>one way this interpretation could be misleading</strong>.<br>
Do not claim causal effects.”</p>
</blockquote>
</div>
</div>
</div>
<hr>
</section>
<section id="example-4-checking-model-assumptions-polished-but-incomplete" class="level3" data-number="9.4.4">
<h3 data-number="9.4.4" class="anchored" data-anchor-id="example-4-checking-model-assumptions-polished-but-incomplete"><span class="header-section-number">9.4.4</span> Example 4: Checking model assumptions <em>(polished but incomplete)</em></h3>
<blockquote class="blockquote">
<p>“I’m using a Poisson mixed-effects model for count data with repeated measurements across sites. Can you explain the assumptions of this model and whether it’s appropriate for my analysis?”</p>
</blockquote>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="Click to reveal a stronger prompt (TRACE)">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Click to reveal a stronger prompt (TRACE)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Missing tags:</strong> [C]<br>
<strong>Rubric tags addressed:</strong> [T] [R] [A] [C] [E]</p>
<blockquote class="blockquote">
<p>“Act as an <strong>ecology methods advisor</strong>. I’m using a <strong>Poisson GLMM</strong> for count data with <strong>repeated measures per site</strong>.<br>
List the <strong>key assumptions</strong>, propose <strong>2–3 diagnostics</strong> to evaluate them, and explain what <strong>pattern in the diagnostics</strong> would indicate a serious problem.<br>
If information is missing, list what you need rather than guessing.”</p>
</blockquote>
</div>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/project_scoping.html" class="pagination-link" aria-label="Project Scoping">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Project Scoping</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->




</body></html>