[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantitative Analysis of (Messy) Field Data",
    "section": "",
    "text": "Essential Course Information",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Information</span>"
    ]
  },
  {
    "objectID": "index.html#essential-course-information",
    "href": "index.html#essential-course-information",
    "title": "Quantitative Analysis of (Messy) Field Data",
    "section": "",
    "text": "Instructor\nPatrick Kelley\n\n\n\n\nEmail\njkelle24@uwyo.edu\n\n\nSchedule\nTu / Th, 11:00–12:15 MT\n\n\nDates\n20-Jan-2026 to 08-May-2026\n\n\nMeeting Type\nsynchronous remote\n\n\nLocation\nJoin via Zoom\n\n\nCommunication\nSlack (private link sent to your email)",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Information</span>"
    ]
  },
  {
    "objectID": "index.html#quicklinks",
    "href": "index.html#quicklinks",
    "title": "Quantitative Analysis of (Messy) Field Data",
    "section": "Quicklinks",
    "text": "Quicklinks\nCollaborative Statistics References\n\nThis course was created using Quarto (via R Studio) using custom CSS and HTML.\n\n\n\n\n\n\nCautionAI usage transparency\n\n\n\n\n\nIn the construction of this website, GenAI (via ChatGPT) was used in the following ways:\n\nGenerating graphics of cryptid jackalope species. This was part of an exercise in prompt engineering—specifically, learning how to design minimalist prompts that produce consistent visual themes across all outputs.\nConverting the Canvas-based course site into Quarto markdown. This included restructuring content, standardizing headers, and translating existing materials into a reproducible, version-controlled format (for hosting on GitHub).\nAssistive learning of custom CSS, in parallel with consulting online CSS documentation and manuals (i.e., as a tutor and debugger, not a design authority).\nReformatting and updating existing tables, including updating of revised dates, assignments, and course logistics.\nError-checking and troubleshooting markdown and Quarto code. This was necessary during site builds.\nImproving organization across course components. This included suggestions for cross-referencing related pages and identifying places where additional examples or clarifications would improve learning outcomes.\nEvaluating pedagogical alignment. This involved getting feedback on readability, cognitive load, and whether learning objectives were being met by the material being presented.\nEditorial support to ensure that tone and level of explanatory detail was appropriate for graduate students. This included tightening some language and reducing informational redundancy across pages.\n\nGenAI was used as an assistive tool throughout; it was not used as a content authority, decision-maker, or substitute for subject-matter expertise. All instructional choices, interpretations, and final edits remain the responsibility of the instructor (in accordance with AI Use Policy).",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Information</span>"
    ]
  },
  {
    "objectID": "chapters/course_intro.html",
    "href": "chapters/course_intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "2.1 Welcome to Quantitative Analysis of (Messy) Field Data!\nThanks for joining us this term! I couldn’t be more pleased at the large size of the class this term! This means that there are more perspectives to help guide us through the following phases of data analysis:\nThe complexity of the project, difficulty of field conditions, or an impending deadline can make the jumps from data collection to inference horribly daunting to young and old researchers alike. Our joint goal in this course is to become more comfortable with each of these steps, so that we not only work more efficiently but we also know a bit more about how to sense of our complex world. It is my sincerest hope that this course will not only teach you some about statistics (and some statistical traps) but that it will also give you a unique opportunity to work with your peers as you delve into the myriad issues that inevitably arise in data analysis. Working together means that we must first acknowledge that each one of us assimilates new material and produces syntheses in varied ways. All I ask is that each of you",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/course_intro.html#welcome-to-quantitative-analysis-of-messy-field-data",
    "href": "chapters/course_intro.html#welcome-to-quantitative-analysis-of-messy-field-data",
    "title": "2  Introduction",
    "section": "",
    "text": "Messy field or lab data → processed data → models → inference",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/course_intro.html#course-objectives",
    "href": "chapters/course_intro.html#course-objectives",
    "title": "2  Introduction",
    "section": "2.2 Course Objectives",
    "text": "2.2 Course Objectives\nBy the end of this course, you should be able to:\n\nThink quantitatively about messy ecological data. You should be on your way to developing a habit of translating real-world ecological questions into quantitative frameworks, while explicitly acknowledging uncertainty and bias in estimation and measurement.\nDistinguish between questions/hypotheses, data, and inferences. You should be able to (1) clearly separate ecological hypotheses, the data actually collected, and the quantities being estimated, and (2) understand why these distinctions matter for interpretation and decision-making.\nUnderstand the processes that generate data. You should be able to recognize how different study designs, variation in detection, observer effects, instrument error, and data processing shape and constrain the structure of ecological datasets.\nSelect, build, and critique statistical models as scientific tools. You should be comfortable choosing and using statistical models not as black boxes, but as explicit representations of assumptions about ecological processes, variation, and causal structure. You should never blindly choose a statistical model again!\nInterpret results in ecological —not just statistical— terms. You should be able to conceptually move beyond p-values and coefficients to clearly articulate what your results mean biologically, mechanistically, and practically.\nBe comfortable applying causal –and not just correlational– reasoning. You should be able to use causal thinking (conceptual models and directed acyclic graphs) to evaluate what can —and ehat cannot— be inferred from observational and experimental data.\nCommunicate quantitative results clearly, transparently, and honestl.y Present analyses, figures, and conclusions in ways that are transparent, reproducible, and appropriate for scientific audiences.\nDevelop durable, reproducible analytical workflows. You should be increasingly comfortable with good data-science practices that support clarity, versioning (even though we will not delve into GitHub this term), and reusability of analyses.\nDevelop new confidence working with unfamiliar, complex, imperfect datasets. You should leave this course better prepared to engage with real ecological data —without expecting it to be clean, complete, or simple.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/course_intro.html#topics-covered",
    "href": "chapters/course_intro.html#topics-covered",
    "title": "2  Introduction",
    "section": "Topics covered",
    "text": "Topics covered\nThe course covers the following topics, roughly in the following order:\n\nMetrology: measurands, measurement error, uncertainty, and data quality\n\nExploratory data analysis of messy data\n\nGeneralized Linear Models (GLMs): theory and implementation\n\nModel comparison using AIC and information-theoretic approaches\n\nGeneralized Linear Mixed Models (GLMMs) and effective sample size\n\nGeneralized Additive Models (GAMs)\n\nGeneralized Additive Mixed Models (GAMMs)\n\nModeling spatial and temporal heterogeneity\n\nStructural Causal Modeling (SCM) and causal diagrams\n\nPrediction, uncertainty propagation, and model validation\n\nSynthesis of analytical results and justification of inference\n\nTables, figures, and reporting standards for quantitative results\n\nWriting defensible and interpretable Results sections\n\nGiven this ambitious scope, we may only scratch the surface of some topics. Even our cursory treatment is aimed at convincing you why these subjects matter for scientists who have messy data.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/course_intro.html#what-is-new-this-term-spring-2026",
    "href": "chapters/course_intro.html#what-is-new-this-term-spring-2026",
    "title": "2  Introduction",
    "section": "2.3 What is new this term (Spring 2026)?",
    "text": "2.3 What is new this term (Spring 2026)?\nFor Spring 2026, I have added attention to new topics that improve both efficiency of analysis workflows and our ability to understand causality at a deeper level. Specifically, I have chosen to add course components on:\n\nUsing large-language models (LLMs) –via ChatGPT– to improve analytical workflows. This term, I have integrated ChatGPT into the course as a way to support the process of analysis rather than to automate the analysis itself. Many of the hardest parts of quantitative work happen outside of writing code: figuring out why R code isn’t behaving as expected, checking whether an interpretation actually follows from a model, troubleshooting an obscure error message, or getting feedback on how tp clearly document a decision. Used carefully, ChatGPT can act like a sounding board for troubleshooting, sanity-checking, and refining explanations without taking over your critical thinking. Throughout the course, I have deliberately constrained ChatGPT’s role and scope and have tailored its guardrails to match the course progression. In other words, ChatGPT is used to help improve analytical workflow and decision-making, not to generate results or write code on a student’s behalf. We will work together to assess the utility of this tool as the term advances.\n\n\n\n\nUsing large-language models (LLMs) to improve teaching at scale. What does this mean? In past terms, between 10-15 students have been enrolled in this course. This term, I have allowed 26 students to enroll. Without a Teaching Assistant, this spawns a significant issue of scale. This is solvable if we use AI as a helpful tool. So, after spending some time as an LLM-consultant and tester, I decided to explicitly integrate chatGPT’s LLMs into my teaching/grading workflow. This means that students will use a custom GPT that I created specifically for ZOO/ECOL-5500 called JackalopeGPT (using ChatGPT) to run checks on their work prior to submission; this will solve some of the “tuning” issues (with codes, grammar, clarity, etc.) that I have seen in student submissions in previous years.\n\n\n\n\n\n\nStructural Causal Models (SCMs) I added Structural Causal Models (SCMs) at the end of the course to give us a way to think more clearly about complex systems where multiple variables influence each other at the same time. In the first part of the course, students will see the limits of fitting separate models (e.g. GLMs, GLMMs, GAMMs) for singular response variables; those models can work individually, but they often miss shared drivers, indirect effects, or how pieces of the complex system of exogenous and endogenous factors fit together. SCMs give us a way to lay out those relationships explicitly and analyze them as a connected structure (as is present in natural systems) rather than as a collection of isolated models. The goal isn’t to replace the modeling approaches we’ve already used but to improve inference by making our assumptions about the system clear and coherent.\nJackalopes! This course corrects a long-standing perspective that (1) jackalopes had deer-like antlers (Fig. 1), and (2) there was only a single species of jackalopes (Fig. 2). We will use the newly discovered cryptid ecosystem for course exercises and examples.\n\n\n\n\nFigure 1. Illustrations of the correct and incorrect ornament morphology of jackalopes.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html",
    "href": "chapters/syllabus.html",
    "title": "3  Syllabus",
    "section": "",
    "text": "3.1 Location and meeting times\nTuesday/Thursday on Zoom; 11:00AM - 12:15PM (Mountain Time) Spring term 2026",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html#office-hours",
    "href": "chapters/syllabus.html#office-hours",
    "title": "3  Syllabus",
    "section": "3.2 Office hours",
    "text": "3.2 Office hours\nDue to the nature of the course, I will not have specific office hours for the course. I have extended class times (after our weekly meetings) to allow more time to ask questions and for one-on-one work. These are optional and may be canceled in some weeks depending on your interest in meeting.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html#prerequisites",
    "href": "chapters/syllabus.html#prerequisites",
    "title": "3  Syllabus",
    "section": "3.3 Prerequisites",
    "text": "3.3 Prerequisites\nTo ensure your success in this course, the following are required: - You must have a dataset to be analyzed this semester. This is very important. This class will only cover data reformatting; we will not cover data processing (except as necessary in specific cases). - Your data analysis must not be used in another (past or present). - You must be at least in your second year of graduate school. - You must have some exposure to using the Program R (tidyverse preferred, but base R is nice too). - You must have taken a statistics course in the last five years.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html#assessment-and-grading-standards",
    "href": "chapters/syllabus.html#assessment-and-grading-standards",
    "title": "3  Syllabus",
    "section": "3.4 Assessment and Grading Standards",
    "text": "3.4 Assessment and Grading Standards\nThis course is graded as Pass or Fail (technically “Satisfactory” or “Unsatisfactory”). To pass the course you need to do the following:\n\nParticipate at least 80% of the class meetings. Simply inform me of your absences (for health reasons, field research, etc.), and then do what you can to catch up with the work.\nTurn in all assignments on their due dates (see Course Calendar) and receive a Green Light on all assignment submissions by the end of term (see Assignments & Grading). This is especially critical until Spring Break, after which there will be more flexibility in your schedule.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html#attendanceparticipation-policy",
    "href": "chapters/syllabus.html#attendanceparticipation-policy",
    "title": "3  Syllabus",
    "section": "3.5 Attendance/Participation Policy",
    "text": "3.5 Attendance/Participation Policy\nThis is a graduate level course, and you are here for your own benefit. That being said, I expect you to come to class, stay engaged with the material, and not only learn how to do your own analysis but understand other types of data and analyses by working with your group members. If you do this, you should have analyzed your own data by the end of the semester and have part of a manuscript completed. Please email me ahead of time when you will be unable to attend class for a valid reason.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html#how-to-succeed-in-the-course-beyond-your-wildest-and-funniest-dreams",
    "href": "chapters/syllabus.html#how-to-succeed-in-the-course-beyond-your-wildest-and-funniest-dreams",
    "title": "3  Syllabus",
    "section": "3.6 How to succeed in the course (beyond your wildest and funniest dreams)",
    "text": "3.6 How to succeed in the course (beyond your wildest and funniest dreams)\nGraduate school can be considerably challenging, as everyone is attempting to juggle research, teaching, classes, health, and family, all while coping with unexpected stressors. Course information is flying at you from every direction; there are many specific terms and concepts that you need to learn and operationalize. So, here are some reminders for you (even though I know you don’t need these):\n\nAsk questions! Even though there are no exams, take copious notes and work collaboratively to build course notes.\nDon’t be afraid to redirect the flow of the course. 5000-level courses should be flexible and fun. I want to give you time to think about and discuss the material. I’m willing to alter the pace of the course, change the order of topics, or devise new exercises for you. This is intended to be fun (while simultaneously transforming you into analytical gurus)! So, just talk to me about how I can help!\nRead all the material in this course guidebook. Many online courses require much more reading; this one does not.\nShow up to as many of the synchronous (Zoom) discussions as you can. When we meet together online, our goal will be to solidify everyone’s understanding of different concepts and how they are linked. These concepts will be useful as you navigate your own analysis project.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html#expectations",
    "href": "chapters/syllabus.html#expectations",
    "title": "3  Syllabus",
    "section": "3.7 Expectations",
    "text": "3.7 Expectations\nAs your instructor, you should expect me to:\n\nTry my very hardest to make the course go smoothly (the reason you now have this nice new online course guide); but please be prepared for the inevitable hiccups. No matter how hard we all try, there always seem to be a few obstacles (like internet going down for a couple of hours when we’re on Zoom).\nRespond to questions within 24 hours during the work week. However, I likely will not respond during the weekend (unless there is an urgent matter).\nRespect you not only as a learner but as a colleague.\nUnderstand that these are strange and sometimes unforgiving times. We all have varying levels of tolerance and resistance to stress. If you are having a hard time for whatever reason, please communicate with me. I suck at judging, but I can do a hell of a job listening and working with you to solve a problem.\n\nAs a student, you are expected to:\n\nBe respectful of everyone in the class, including me.\nAsk for help if needed.\nTreat your presence in the classroom and your enrollment in this course as you would a job; Act professionally, arrive on time, pay attention, complete your work in a timely and professional manner, and treat your learning seriously.\nUnderstand that everyone is going through different things (family events, etc.), and be understanding of each other.\nBe engaged in the course.\nBe engaged within your assigned groups and help each other learn. Teaching another group member something you know solidifies your own knowledge and also sets you up to be a great future colleague.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html#r-code-readings-and-discussion-sections",
    "href": "chapters/syllabus.html#r-code-readings-and-discussion-sections",
    "title": "3  Syllabus",
    "section": "3.8 R Code, readings, and discussion sections",
    "text": "3.8 R Code, readings, and discussion sections\nAll R code required for both instruction and hands-on exercises is available within this course book. Unlike past versions of this course, the present iteration no longer has traditional lectures. That said, I may respond to your questions by creating mini-presentations for you. I will share such material immediately after our discussions.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html#classroom-climate-and-conduct",
    "href": "chapters/syllabus.html#classroom-climate-and-conduct",
    "title": "3  Syllabus",
    "section": "3.9 Classroom Climate and Conduct",
    "text": "3.9 Classroom Climate and Conduct\nAgain, you will be respectful towards your classmates and your instructors. Spirited debate and disagreement are to be expected in any classroom, and all perspectives will be heard, but we will behave civilly and with respect towards one another. Personal attacks, offensive language, name-calling, and dismissive gestures (eye-rolling, saying “whatever”, etc.) are not warranted in a learning atmosphere. Plus, in my opinion, such behavior shows an ability to problem-solve, which is counter to the mission of any university. As your instructor, I have the right to dismiss you from the classroom if you engage in disrespectful or disruptive behavior. Lastly, for the privacy of your fellow students, please do not record the lectures (unless with permission of the instructor).\n\n\n\n\n\n\nNoteA note on knowledge-sharing\n\n\n\n\n\nOur classroom is a shared intellectual space. Questions, mistakes, and partial understanding are part of learning. Please remember that supporting one another’s intellectual growth matters more than performative corrections or demonstrations of expertise.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html#classroom-statement-on-diversity",
    "href": "chapters/syllabus.html#classroom-statement-on-diversity",
    "title": "3  Syllabus",
    "section": "3.10 Classroom Statement on Diversity",
    "text": "3.10 Classroom Statement on Diversity\nThe University of Wyoming values an educational environment that is diverse, equitable, and inclusive. The diversity that students and faculty bring to class, including age, country of origin, culture, disability, economic class, ethnicity, gender identity, immigration status, linguistic, political affiliation, race, religion, sexual orientation, veteran status, worldview, and other social and cultural diversity is valued, respected, and considered a resource for learning. we understand that our UW community members represent a rich variety of backgrounds and perspectives. We are committed to providing an atmosphere for learning that respects diversity of all types. While working together to build this community, we ask all members–from students to staff to faculty–to:\n\nBe transparent about pre-existing biases and beliefs.\nDo not hesitate to share their unique experiences and perspectives.\nBe open to the views of others.\nHonor the uniqueness of their colleagues.\nAppreciate the opportunity that we have to learn from each other in this community.\nValue each other’s opinions and communicate in a respectful manner.\nKeep confidential any discussions of a personal (or professional) nature.\nUse this opportunity together to discuss ways in which we can create an inclusive environment in this course and across the University community.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html#duty-to-report",
    "href": "chapters/syllabus.html#duty-to-report",
    "title": "3  Syllabus",
    "section": "3.11 Duty to Report",
    "text": "3.11 Duty to Report\nUW faculty are committed to supporting students and upholding the University’s non-discrimination policy. Under Title IX, discrimination based upon sex and gender is prohibited. If you experience an incident of sex- or gender-based discrimination, we encourage you to report it. While you may talk to a faculty member, understand that as a “Responsible Employee” of the University, the faculty member is required to report information you share about the incident to the University’s Title IX Coordinator (you may choose whether you or anyone involved is identified by name). If you would like to speak with someone who may be able to afford you privacy or confidentiality, there are people who can meet with you. Faculty can help direct you or you may find info about UW policy and resources at http://www.uwyo.edu/reportit. While we want you to feel comfortable coming to us with issues you may be struggling with or concerns you may be having, please be aware that we have some reporting requirements that are part of our job requirements at UW. You do not have to go through the experience alone. For example, if you inform us of an issue of sexual harassment, sexual assault, or discrimination we will keep the information as private as we can, but we am required to bring it to the attention of the institution’s Title IX Coordinator. If you would like to talk to those offices directly, you can contact Equal Opportunity Report and Response (Bureau of Mines Room 319, 766-5200, report-it@uwyo.edu, www.uwyo.edu/reportit). Additionally, you can also report incidents or complaints to the UW Police Department. You can also get support at the STOP Violence program (stopviolence@uwyo.edu, www.uwyo.edu/stop, 766-3296) (or SAFE Project (www.safeproject.org, campus@safeproject.org, 766-3434, 24-Hour hotline: 745-3556). Assistance and resources are available, and you are not required to make a formal complaint or participate in an investigation to access them. Another common example is if you are struggling with an issue that may be traumatic, or under unusual stress. We will likely inform the Dean of Students Office or Counseling Center. If you would like to reach out directly to them for assistance, you can contact them by going to www.uwyo.edu/dos/uwyocares.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html#disability-statement",
    "href": "chapters/syllabus.html#disability-statement",
    "title": "3  Syllabus",
    "section": "3.12 Disability Statement",
    "text": "3.12 Disability Statement\nIf you have a physical, learning, sensory or psychological disability and require accommodations, please let me know as soon as possible. You will need to register with, and provide documentation of your disability to University Disability Support Services (UDSS) in SEO, room 330 Knight Hall.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/syllabus.html#academic-honesty",
    "href": "chapters/syllabus.html#academic-honesty",
    "title": "3  Syllabus",
    "section": "3.13 Academic Honesty",
    "text": "3.13 Academic Honesty\nThe University of Wyoming is built upon a strong foundation of integrity, respect and trust. All members of the university community have a responsibility to be honest and the right to expect honesty from others. Any form of academic dishonesty is unacceptable to our community and will not be tolerated [from the University Catalog]. Teachers and students should report suspected violations of standards of academic honesty to the instructor, department head, or dean. Other University regulations can be found here",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "chapters/calendar_sp26.html",
    "href": "chapters/calendar_sp26.html",
    "title": "4  Course calendar",
    "section": "",
    "text": "4.1 Calendar overview\nUse the calendar table below to see what’s coming each week; simply click a week (first column link) to jump to full details, and then expand sections to see what to do before, during, and after class. This calendar may change slightly as we progress through the term. You will receive immediate notification of any and all changes.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Course calendar</span>"
    ]
  },
  {
    "objectID": "chapters/calendar_sp26.html#calendar-overview",
    "href": "chapters/calendar_sp26.html#calendar-overview",
    "title": "4  Course calendar",
    "section": "",
    "text": "Note\n\n\n\nAll Milestone Assignments due by end of day on Friday.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nTopics\nIn-class exercise\nMilestone assignment (due Friday)\nStress level\nGrade weight (%)\n\n\n\n\nWeek 119-Jan-2026\nCourse intro; RStudio setup; AI guardrails\nProject scoping discussion\n—\nVery low\n0\n\n\nWeek 226-Jan-2026\nFile structure; reproducible workflows; AI logs\nFile audit walkthrough\nAnalysis Concept Note\nLow\n5\n\n\nWeek 302-Feb-2026\nData exploration; measurement & uncertainty\nExploratory data analysis walkthrough\n—\nVery low\n0\n\n\nWeek 409-Feb-2026\nGLMs (theory + practice)\nGLM exercise\nData Readiness Note\nLow\n10\n\n\nWeek 516-Feb-2026\nGLMs; AIC & information theory\nModel comparison exercise\n—\nLow\n5\n\n\nWeek 623-Feb-2026\nGLMMs; effective sample size\nGLMM exercise\n—\nModerate\n15\n\n\nWeek 702-Mar-2026\nGAMs\nGAM exercise\nWorking Model (draft)\nModerate\n0\n\n\nWeek 809-Mar-2026\nGAMMs; spatial & temporal heterogeneity\nModel refinement exercise\nWorking Model (final lock)\nModerate\n15\n\n\nWeek 916-Mar-2026\nStudent Spring Break\n—\n—\nNone\n0\n\n\nWeek 1023-Mar-2026\nStructural Causal Modeling (SCM)\nCausal diagram critique\n—\nLow\n10\n\n\nWeek 1130-Mar-2026\nInstructor Spring Break\n—\n—\nNone\n0\n\n\nWeek 1206-Apr-2026\nPrediction & uncertainty\nPrediction checks\nInterpretation Memo\nLow\n10\n\n\nWeek 1313-Apr-2026\nSynthesis & justification\nPeer + AI review\n—\nModerate\n0\n\n\nWeek 1420-Apr-2026\nTables, figures, reporting standards\nTable/figure workshop\nResults Section\nLow\n10\n\n\nWeek 1527-Apr-2026\nWriting Results sections\nDraft clinic\nFull Draft\nModerate\n15\n\n\nWeek 1604-May-2026\nReflection & closure\nCourse wrap-up\nRevision Plan (not executed)\nNone\n5",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Course calendar</span>"
    ]
  },
  {
    "objectID": "chapters/calendar_sp26.html#weekly-information",
    "href": "chapters/calendar_sp26.html#weekly-information",
    "title": "4  Course calendar",
    "section": "4.2 Weekly Information",
    "text": "4.2 Weekly Information\nClick to expand sections below to see expectations before, during, and after class.\n\n\n\n\n\n\nTipWeek 1 (19-Jan-2026)\n\n\n\n\n\nTopics: Course introduction; RStudio setup; AI guardrails\nStress level: Very low\nGrade weight: 0%\n\nBefore class\n\nAbsolutely nothing.\n\n\n\nIn class\n\nCourse overview and expectations\nReview syllabus\nRead AI policy and documentation expectations\nProject scoping discussion\n\n\n\nAfter class\n\nNo submission due\nInstall R and RStudio\nRead AI use and documentation expectations\nBegin gathering your dataset files\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 2 (26-Jan-2026)\n\n\n\n\n\nTopics: File structure; reproducible workflows; AI logs\nStress level: Low\nGrade weight: 5%\n\nBefore class\n\nReview example project directory structures\nRead guidance on reproducible workflows\n\n\n\nIn class\n\nFile audit walkthrough\nDiscussion of AI interaction logging\n\n\n\nAfter class\n\nSubmit: Analysis Concept Note\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 3 (02-Feb-2026)\n\n\n\n\n\nTopics: Data exploration; measurement & uncertainty\nStress level: Very low\nGrade weight: 5%\n\nBefore class\n\nSkim examples of exploratory data analysis (EDA)\nReview notes on uncertainty and measurement error\n\n\n\nIn class\n\nExploratory data analysis walkthrough\nDiscussion of data limitations and noise\n\n\n\nAfter class\n\nNo submission due\nBegin informal exploration of your own data\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 4 (09-Feb-2026)\n\n\n\n\n\nTopics: GLMs (theory + practice)\nStress level: Low\nGrade weight: 10%\n\nBefore class\n\nRead GLM conceptual overview\nReview examples of common link functions\n\n\n\nIn class\n\nGLM exercise\nTranslating scientific questions into model form\n\n\n\nAfter class\n\nSubmit: Data Readiness Note\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 5 (16-Feb-2026)\n\n\n\n\n\nTopics: GLMs; AIC & information theory\nStress level: Low\nGrade weight: 5%\n\nBefore class\n\nReview information-theoretic model comparison\nRead example AIC workflows\n\n\n\nIn class\n\nModel comparison exercise\nInterpreting relative support\n\n\n\nAfter class\n\nNo submission due\nRefine candidate model sets\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 6 (23-Feb-2026)\n\n\n\n\n\nTopics: GLMMs; effective sample size\nStress level: Moderate\nGrade weight: 15%\n\nBefore class\n\nRead GLMM overview\nReview motivation for random effects\n\n\n\nIn class\n\nGLMM exercise\nDiscussion of pseudoreplication and effective sample size\n\n\n\nAfter class\n\nNo submission due\nBegin transitioning models to mixed frameworks where appropriate\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 7 (02-Mar-2026)\n\n\n\n\n\nTopics: GAMs\nStress level: Moderate\nGrade weight: 0%\n\nBefore class\n\nReview motivation for smooth terms\nRead conceptual introduction to GAMs\n\n\n\nIn class\n\nGAM exercise\nInterpreting smooths vs parametric effects\n\n\n\nAfter class\n\nSubmit: Working Model (draft)\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 8 (09-Mar-2026)\n\n\n\n\n\nTopics: GAMMs; spatial & temporal heterogeneity\nStress level: Moderate\nGrade weight: 15%\n\nBefore class\n\nReview examples of spatial and temporal structure\nRead GAMM case studies\n\n\n\nIn class\n\nModel refinement exercise\nDiagnosing remaining structure in residuals\n\n\n\nAfter class\n\nSubmit: Working Model (final lock)\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 9 (16-Mar-2026)\n\n\n\n\n\nTopics: Student Spring Break\nStress level: None\nGrade weight: 0%\n\nNotes\n\nNo class\nNo assignments due\nRecommended: rest, catch up, or light review if needed\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 10 (23-Mar-2026)\n\n\n\n\n\nTopics: Structural Causal Modeling (SCM)\nStress level: Low\nGrade weight: 10%\n\nBefore class\n\nRead SCM overview and motivation\nReview example causal diagrams\n\n\n\nIn class\n\nCausal diagram critique\nDiscussion of assumptions and identification\n\n\n\nAfter class\n\nNo submission due\nConsider how SCM reframes your modeling decisions\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 11 (30-Mar-2026)\n\n\n\n\n\nTopics: Instructor Spring Break\nStress level: None\nGrade weight: 0%\n\nNotes\n\nNo class\nNo assignments due\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 12 (06-Apr-2026)\n\n\n\n\n\nTopics: Prediction & uncertainty\nStress level: Low\nGrade weight: 10%\n\nBefore class\n\nReview prediction vs inference distinctions\nRead examples of uncertainty communication\n\n\n\nIn class\n\nPrediction checks\nEvaluating extrapolation risk\n\n\n\nAfter class\n\nSubmit: Interpretation Memo\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 13 (13-Apr-2026)\n\n\n\n\n\nTopics: Synthesis & justification\nStress level: Moderate\nGrade weight: 0%\n\nBefore class\n\nReview synthesis examples from prior studies\n\n\n\nIn class\n\nPeer + AI review\nJustifying analytical decisions\n\n\n\nAfter class\n\nNo submission due\nPrepare figures and tables for results\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 14 (20-Apr-2026)\n\n\n\n\n\nTopics: Tables, figures, reporting standards\nStress level: Low\nGrade weight: 10%\n\nBefore class\n\nReview reporting guidelines\nExamine good and bad figure examples\n\n\n\nIn class\n\nTable/figure workshop\nEmphasis on clarity and restraint\n\n\n\nAfter class\n\nSubmit: Results Section\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 15 (27-Apr-2026)\n\n\n\n\n\nTopics: Writing Results sections\nStress level: Moderate\nGrade weight: 15%\n\nBefore class\n\nReview example Results sections\nReflect on narrative flow\n\n\n\nIn class\n\nDraft clinic\nFocused feedback on structure and interpretation\n\n\n\nAfter class\n\nSubmit: Full Draft\n\n\n\n\n\n\n\n\n\n\n\nTipWeek 16 (04-May-2026)\n\n\n\n\n\nTopics: Reflection & closure\nStress level: None\nGrade weight: 5%\n\nBefore class\n\nReview feedback on full draft\n\n\n\nIn class\n\nCourse wrap-up\nReflection on analytical growth\n\n\n\nAfter class\n\nSubmit: Revision Plan (not executed)",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Course calendar</span>"
    ]
  },
  {
    "objectID": "chapters/ai_policy.html",
    "href": "chapters/ai_policy.html",
    "title": "5  GenAI Use Guidelines",
    "section": "",
    "text": "5.1 Timeline\nResponsible use of generative artificial intelligence (GenAI)\nThis documented was updated on 06-January-2026. This document should be reviewed periodically, particularly when adopting new GenAI tools or when disciplinary norms evolve (while resisting harmful, shifting baselines).",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>GenAI Use Guidelines</span>"
    ]
  },
  {
    "objectID": "chapters/ai_policy.html#purpose",
    "href": "chapters/ai_policy.html#purpose",
    "title": "5  GenAI Use Guidelines",
    "section": "5.2 Purpose",
    "text": "5.2 Purpose\nThis document reviews principles, guard rails, and documentation practices for the responsible use of generative artificial intelligence (GenAI) tools in scientific research and analysis. One such GenAI tool that most of us are familiar with is ChatGPT (Generative Pre-trained Transformer), a GenAI model that can detect (and arguably understand) and generate human-like text by predicting what comes next in a sentence. Large Language Models (LLMs) are very advanced GenAI systems trained on absolutely massive amounts of text to answer complex questions, write in certain rhetorical tones, summarize information, or have conversations in natural language. Given this tool’s widespread utility, it can certainly be misused. Therefore, the guidelines below attempt to ensure that GenAI augments human reasoning without compromising scientific validity, reproducibility, or accountability. In all aspects of the present academic work, GenAI tools like ChatGPT are therefore treated as assistive tools –comparable to statistical software (like R) or calculators– not as autonomous analysts or skilled authors.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>GenAI Use Guidelines</span>"
    ]
  },
  {
    "objectID": "chapters/ai_policy.html#core-principles-of-responsible-use-of-genai",
    "href": "chapters/ai_policy.html#core-principles-of-responsible-use-of-genai",
    "title": "5  GenAI Use Guidelines",
    "section": "5.3 Core principles of responsible use of GenAI",
    "text": "5.3 Core principles of responsible use of GenAI\n\nAccountability: The human researcher retains full responsibility for –and is held accountable for– all analytical decisions, interpretations, text and code, and inference. The use of GenAI does not relieve any burdens of authorship, responsibility, or liability. Importantly, this means that the human researcher is allowed –and, in most cases, is encouraged– to use AI-produced code, as long as the research has vetted and error-checked. This likewise assumes that the researcher accepts responsibility for any and all errors arising from AI assistance. That is, GenAI may accelerate work, but it may not replace understanding. If a researcher cannot defend a decision without the GenAI present, the decision is invalid.\nScientific Primacy: Scientific reasoning precedes and constrains GenAI use. Hypotheses, data-generating assumptions, and model structures must be defined by the researcher. GenAI may clarify or critique these decisions but may not create them from scratch without human justification.\nTransparency: All GenAI use must be documented in a way that allows another scientist to understand how GenAI influenced the work. GenAI-assisted reasoning must be distinguishable from original analysis.\nReproducibility: All results must be reproducible without access to GenAI tools. Data, code, and associated documentation must be sufficient to reproduce results independently. GenAI may assist development but must not be a hidden dependency.\nProportionality: The level of documentation naturally should be proportional to the influence of GenAI. Minor stylistic assistance requires minimal logging, while conceptual or analytical assistance requires a larger volume of explicit documentation and justification.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>GenAI Use Guidelines</span>"
    ]
  },
  {
    "objectID": "chapters/ai_policy.html#what-is-allowed-and-what-is-not-allowed",
    "href": "chapters/ai_policy.html#what-is-allowed-and-what-is-not-allowed",
    "title": "5  GenAI Use Guidelines",
    "section": "5.4 What is allowed, and what is not allowed?",
    "text": "5.4 What is allowed, and what is not allowed?\n\nPermitted Uses of GPTs in Scientific Work\n\nConceptual Clarification: GenAI may be used to explain statistical concepts, examine modeling assumptions, and interpret model diagnostics (at a broad level).\nPlanning and Reflection: GenAI may assist with refining research questions, generating assumption checklists, stress-testing interpretations, and identifying alternative explanations that are then vetted for ecological sanity by the human researcher.\nWriting Support: GenAI may be used to improve clarity, organization, and tone, and to identify points of ambiguity or inferential overreach. AI absolutely must not invent methods, results, or citations.\nCode Understanding: GenAI may explain what existing code does, diagnose warnings or errors conceptually, and suggest stylistic or reproducibility improvements. AI may not replace independent code comprehension.\n\n\n\n\nProhibited or Restricted Uses of GenAIin Scientific Work\n\nReplacement of Scientific Judgment: GenAI must not be used to select models, error distributions, priors, or random-effects structures without independent human justification, nor to interpret results without verification.\nUndocumented Analysis Generation: GenAI must not generate full end-to-end analytical pipelines without explanation, or produce black-box code whose logic is not understood by the researcher.\nFabrication: GenAI must not be used to invent data, methods, results, or citations, or to create post-hoc justifications unsupported by the analysis.\nOutcome Optimization: GenAI must not be used to iteratively prompt for statistically significant results, improved AIC values, or exaggerated certainty.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>GenAI Use Guidelines</span>"
    ]
  },
  {
    "objectID": "chapters/ai_policy.html#genai-interaction-log",
    "href": "chapters/ai_policy.html#genai-interaction-log",
    "title": "5  GenAI Use Guidelines",
    "section": "5.5 GenAI Interaction Log",
    "text": "5.5 GenAI Interaction Log\n\n5.5.1 Purpose of the Log\nResearchers should maintain an AI Interaction Log alongside their analysis notebook to document meaningful AI involvement in the research process. (This is a required component for students in ZOO/ECOL-5500 starting Spring 2026)\n\nRequired Information: Entries record the date, GenAI tool used, purpose of interaction, nature of assistance provided, key takeaway, and the verification step performed.\nWhen Logging Is Required: Logging is required when GenAI influences model choice, interpretation, methodological justification, or scientific claims. Minor stylistic or grammatical use does not require detailed logging.\nVerification Obligations: Any GenAI-suggested content must be independently verified using primary literature, software documentation, diagnostic checks, or independent reasoning. Unverified AI output must not appear in final analyses.\nAuthorship and Attribution: GenAI tools are not authors and do not receive citation credit. If required by journals or funders, GenAI use may be acknowledged in a neutral Methods or Acknowledgments statement.\nEthical Safeguards: GenAI use must not obscure uncertainty, inflate confidence, reduce methodological transparency, or disadvantage collaborators or students with limited access to AI tools.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>GenAI Use Guidelines</span>"
    ]
  },
  {
    "objectID": "chapters/preparing_yourself.html",
    "href": "chapters/preparing_yourself.html",
    "title": "6  Preparing Yourself",
    "section": "",
    "text": "6.1 What do I need to do to get started in this class?\nTo prepare for the course, here is what you are expected to do by the end of the first week (specific information is below this list):",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Preparing Yourself</span>"
    ]
  },
  {
    "objectID": "chapters/preparing_yourself.html#what-do-i-need-to-do-to-get-started-in-this-class",
    "href": "chapters/preparing_yourself.html#what-do-i-need-to-do-to-get-started-in-this-class",
    "title": "6  Preparing Yourself",
    "section": "",
    "text": "Join the ZOO-5500 Slack (private link sent via email)\nDownload, Install, and set up RStudio Desktop\nGather your dataset files for your analysis\n\n\n6.1.1 Join the ZOO-5500 Slack\nJust click on the list and follow instructions. We will use Slack to encourage ongoing, low-stakes discussion within the class. This will be for sharing questions, ideas, and insights in real time so that learning can continue outside of scheduled class meetings. This allows everyone (even me) to get answers to questions that I might be thinking about at odd times. It also allows for problems to be solved faster; rather than waiting until our synchronous Zoom session to ask about an issue, we can group-think over the course of the week. Remember that this is set up to improve collaboration; it does not mean that anyone should be responding outside of work hours or on the weekends. Below are the preferred channels for different kinds of communication:\n\n#announcements &gt;Read-only channel for important course information like deadlines, corrections, and post-class clarifications. Check this regularly.\n#course-questions &gt;For general course or assignment questions (due dates, unclear wording on websites) that others might also have. Expect peer responses and occasional instructor follow-ups.\n#data-help &gt;For data wrangling and technical data issues (imports, joins, NAs, plots). Not for model choice or interpretation.\n#model-talk &gt;For conceptual questions about models and assumptions. Discussion-focused; no code debugging.\n#analysis-workflow &gt;For questions about reproducibility, organization, reporting, and good analytical habits.\n#ai-use-and-logs For discussing allowed AI use and posting AI interaction logs when requested. No private communication or graded work.\n#papers-good-bad-ugly &gt;For highlighting examples of good and bad analyses in published work.\n#random &gt;For off-topic chat, random links, and fun stuff. This will help keep everything else focused.\n\n\n\n6.1.2 Download, Install, and set up RStudio Desktop\nInstall on your local machine. All coding and file organization will be done in RStudio. Note that the following is a very basic way of creating a set of project folders. You will see boxes with R code. Feel free to copy and run these, if necessary. Here are the basic steps:\n\nDownload and install RStudio Desktop. Navigate to your folder (in this case, your student folder).\nIn “Files” window (lower right panel in RStudio), click “More/Set as Working Directory”. This sets your working directory; this is always a good idea to do.\nCreate a New R Project in your student folder: “File/New Project/Existing Directory”. Name this project appropriately.\nCreate your File structure: Refer to this RStudio tutorial. In this class, we will modify this set of directories to make things a bit easier and more transparent for you. After completing the following steps, place your dataset in your “data/raw_data” folder (after you create it below). Navigate to this folder on your computer and drag-and-drop or copy-paste your data file(s) into this folder.\n\nCreate three folders (one suggested framework):\n\n/data (for raw, processed, clean datasets)\n/r_scripts (for R scripts, each containing a set of related functions)\n/output output (for models, graphs, tables)\n\nWe can do this by staying in our directory (within RStudio) and then using the dir.create function.\n\ndir.create(\"data\")\n\nYou can see your new folder (“data”) appear in the Files in the lower right window within RStudio. Now let’s create the other two folders.\n\ndir.create(\"r_scripts\")\ndir.create(\"output\")\n\nTo help with data processing (i.e. cleaning and organization)–something that we will discuss in coming days within the context of your analytical workflow–, we will create some subfolders within your newly created “data” folder. Let’s do this now. Note how you create a folder within the “data” folder by specifying the path:\n\ndir.create(\"data/raw_data\")\ndir.create(\"data/processed_data\")\ndir.create(\"data/metadata\")\n\nAnd that is how you create a basic R Project in RStudio! What you have done is create a set of folders and subfolders that have names that can be easily understood by other users. Feel free to create other subfolders now. Or, should you not like the file nomenclature used above, change the names to whatever you wish. Just be sure that this structure is as simple as possible so that other users understand what you have done.\nThere is an added benefit to creating an R Project in this way. What you have done is create a minimally reproducible data structure. There are two primary ways this can be accomplished (if you are not familiar with this. First method: A collaborator (or instructor or classmate) can simply navigate to your subfolder, set that as their working directory from within RStudio, and then open the .RProj file. Alternatively, you can create zip your root folder (the one labelled as your name, in this case) and then share your entire analysis, etc. All the recipient would need to do is unzip the folder, open the .Rproj file, and then “Set as Working Directory.”\n\n\n6.1.3 Gather your dataset files for your analysis\nPlace your data in your “data/raw_data” subfolder and then confirm that your files are present by running the list.files function.\n\nlist.files(\"data/raw_data\")\n\n\n\n\n\n\n\nNote\n\n\n\nWorking order means more than a spreadsheet or two.\nA dataset is only complete if it includes metadata. Metadata describe: - what the variables are\n- how the data were collected\n- under what conditions\n- with what assumptions and limitations\nIf you have questions about metadata, I have an old, dedicated lecture on metadata structures, and I strongly encourage you to reach out.\n\n\nYou are now ready to move to the next steps of loading necessary R packages and beginning your journey of data exploration!",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Preparing Yourself</span>"
    ]
  },
  {
    "objectID": "chapters/assignment_grades.html",
    "href": "chapters/assignment_grades.html",
    "title": "Assignments & Grades",
    "section": "",
    "text": "Milestone Assignment descriptions\nThis page first describes the Milestone Assignments referenced in the course calendar. Each section below explains the purpose of the milestone, what to submit, and what “good” typically looks like. Grading rubrics are described at the end of this page.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Assignments & Grades</span>"
    ]
  },
  {
    "objectID": "chapters/assignment_grades.html#milestone-assignment-descriptions",
    "href": "chapters/assignment_grades.html#milestone-assignment-descriptions",
    "title": "Assignments & Grades",
    "section": "",
    "text": "NoteAnalysis Concept Note (Week 2)\n\n\n\n\n\nPurpose:\nLock in a feasible analysis plan early, so you’re not improvising later. This is about scope, clarity, and workflow—not results.\n\nWhat to include\nDownload the Analysis Concept Note template (.qmd)\n\nWorking title (can change later)\nYour focal question (1–3 sentences; plain language)\nStudy system and units of analysis (what is one “row,” conceptually?)\nResponse variable(s) and predictor(s) you expect to use (draft list is fine)\nHypothesized relationships\n\nShort bullets; include directionality when possible\n\nData source and file plan\n\nWhere the data live\n\nWhat you will name files\n\nWhat the folder structure will be\n\nPlanned model family (tentative)\n\ne.g., GLM / GLMM / GAM / GAMM, and why that’s your first guess\n\nPotential complications you already suspect\n\nMissing data, non-independence, zero inflation, seasonality, etc.\n\n\n\n\nSubmission format\n\n1–2 pages (PDF) or a short Quarto/Markdown page\nClear headings (don’t bury the key information)\n\n\n\n“Good” looks like\n\nA question that is answerable with the data you actually have\nReasonable scope for one semester\nA workflow plan that makes your project reproducible from day one\n\n\n\n\n\n\n\n\n\n\n\nNoteData Readiness Note (Week 4)\n\n\n\n\n\nPurpose:\nDemonstrate that your dataset is analysis-ready—or identify exactly what still blocks you. This is your chance to be honest about limitations before modeling.\n\nWhat to include\n\nDataset summary\n\nNumber of rows/observations\n\nKey grouping structure (site, individual, date, etc.)\n\nData dictionary (lightweight)\n\nVariable name → meaning → units → type (numeric, factor, date)\n\nMissingness and exclusions\n\nWhat’s missing, where, and what you did about it (if anything)\n\nMeasurement and uncertainty notes\n\nKnown measurement error, detection limits, observer effects, instrument drift, etc.\n\nBasic Exploratory Data Analysis outputs (minimal but informative)\n\n1–3 plots that reveal structure (distributions, relationships, time trends)\n\nA short paragraph interpreting what matters\n\nReadiness decision\n\n“Ready to model” or “Not ready yet,” with a clear plan to get there\n\n\n\n\nSubmission format\n\n1–2 pages (PDF) or Quarto page with embedded plots\nIn your Quarto-formatted (.qmd) submission, please include the final Evaluation Table (i.e. rubric-tested) output from JackalopeGPT.\n\n\n\n“Good” looks like\n\nYou can explain what each variable means and whether it Is trustworthy\nYou have surfaced the biggest problems early\nYour Exploratory Data Analysis purposeful, not a plot dump\n\n\n\n\n\n\n\n\n\n\n\nNoteWorking Model — Draft (Week 7)\n\n\n\n\n\nPurpose:\nPut a real model on the table. This is a draft: imperfect is fine, but it must be runnable and defensible.\n\nWhat to include\n\nYour current model formula(s) (plain language and/or code notation)\nModel type (GLM, GLMM, GAM, etc.) and why it fits the data structure\nKey diagnostics or checks (draft level)\n\nAnything that suggests it’s “in the ballpark” or clearly broken\n\nOne short interpretation paragraph\n\nWhat the model suggests (careful language; no over-claiming)\n\nA short “known issues” list\n\nWhat you know is wrong or incomplete\n\nWhat you plan to try next\n\n\n\n\nSubmission format\n\nQuarto page (preferred) or PDF with model description and outputs\nInclude enough detail that someone else could reproduce the model from your write-up\nIn your Quarto-formatted (.qmd) submission, please include the final Evaluation Table (i.e. rubric-tested) output from JackalopeGPT.\n\n\n\n“Good” looks like\n\nA runnable model aligned with your question\nHonest diagnostics and a clear plan to improve\n\n\n\n\n\n\n\n\n\n\n\nNoteWorking Model — Final Lock (Week 8)\n\n\n\n\n\nPurpose:\nFreeze the core model so the rest of the semester can focus on prediction, interpretation, and reporting instead of endless tinkering.\n\nWhat to include\n\nFinal model specification\n\nFinal formula, family/link, random effects or smooths, correlation structures if used\n\nJustification\n\nWhy this structure is appropriate for the data and the question\n\nModel checks\n\nA small set of diagnostics you can defend\n\nNotes on remaining limitations\n\nWhat changes are no longer allowed\n\nAfter the lock, presentation and interpretation may improve, but model shopping should stop without compelling justification\n\n\n\n\nSubmission format\n\nQuarto page (preferred) or PDF\nInclude key outputs you will rely on later (even if figures improve)\nIn your Quarto-formatted (.qmd) submission, please include the final Evaluation Table (i.e. rubric-tested) output from JackalopeGPT.\n\n\n\n“Good” looks like\n\nA stable model you can explain to a skeptical reader\nEvidence you tested assumptions (rather than hoping)\n\n\n\n\n\n\n\n\n\n\n\nNoteInterpretation Memo (Week 12)\n\n\n\n\n\nPurpose:\nPractice disciplined interpretation and uncertainty-aware reasoning. This is where you show that you can tell the truth about what the model does—and does not—say.\n\nWhat to include\n\nMain result(s) in plain language\nUncertainty\n\nWhat is uncertain and why\n\nConfidence intervals, credible intervals, prediction intervals, or other appropriate summaries\n\nPrediction vs. inference clarity\n\nAre you predicting new cases, explaining mechanisms, or both?\n\nSensitivity or robustness (lightweight)\n\nOne small check that increases confidence (or reveals fragility)\n\nLimitations\n\nThe most important threats to inference and how they affect interpretation\n\n\n\n\nSubmission format\n\n~1–2 pages (PDF) or Quarto page\nEmphasis on writing quality and intellectual restraint\nIn your Quarto-formatted (.qmd) submission, please include the final Evaluation Table (i.e. rubric-tested) output from JackalopeGPT.\n\n\n\n“Good” looks like\n\nClear, honest claims tied directly to model output\nUncertainty is centered, not hidden\nNo story time beyond what the evidence supports\n\n\n\n\n\n\n\n\n\n\n\nNoteResults Section (Week 14)\n\n\n\n\n\nPurpose:\nDraft the Results section you would submit in a real paper or report: concise, structured, and supported by tables and figures.\n\nWhat to include\n\nShort orienting paragraph\n\nWhat you modeled and what the reader should look for\n\nCore results\n\n2–4 key findings, depending on project scope\n\nTables and/or figures\n\nClean, interpretable, labeled, and referenced in text\n\nMinimal interpretation\n\nState what you found; deeper interpretation comes later or is clearly separated\n\n\n\n\nSubmission format\n\nQuarto page (ideal) or PDF\nInclude figure and table captions\nIn your Quarto-formatted (.qmd) submission, please include the final Evaluation Table (i.e. rubric-tested) output from JackalopeGPT.\n\n\n\n“Good” looks like\n\nFindings are understandable without reading your code\nFigures and tables do real work\nClaims match the evidence shown\n\n\n\n\n\n\n\n\n\n\n\nNoteFull Draft (Week 15)\n\n\n\n\n\nPurpose:\nAssemble a complete, coherent draft that reads like a real scientific product. Structure and flow matter here.\n\nWhat to include\n\nAt minimum: Introduction, Methods, Results, Discussion (or equivalent)\nConsistent terminology\n\nVariable names, units, and definitions do not drift\n\nAll figures and tables in near-final form\nReferences and citations, as appropriate\n\n\n\nSubmission format\n\nQuarto render (HTML or PDF preferred)\nEnsure figures and tables are legible and captioned\nIn your Quarto-formatted (.qmd) submission, please include the final Evaluation Table (i.e. rubric-tested) output from JackalopeGPT.\n\n\n\n“Good” looks like\n\nA document that could be revised into something publishable\nClear logic and honest uncertainty\nNo missing major components\n\n\n\n\n\n\n\n\n\n\n\nNoteRevision Plan (Not Executed) (Week 16)\n\n\n\n\n\nPurpose:\nDemonstrate that you can revise strategically. You will not execute revisions; you will propose them.\n\nWhat to include\n\nTop five revision priorities\n\nRanked, with a sentence explaining why each matters\n\nWhat you would change (specific)\n\n“Rewrite paragraph X to clarify Y”\n\n“Replace Figure 2 with a plot that shows Z”\n\nWhat evidence you would need\n\nAdditional checks, plots, sensitivity analyses, etc.\n\nIf you had 10 more hours\n\nWhat would you do first?\n\nIf you had 40 more hours\n\nWhat would you do that you cannot do now?\n\n\n\n\nSubmission format\n\n1 page (PDF) or short Quarto page\nIn your Quarto-formatted (.qmd) submission, please include the final Evaluation Table (i.e. rubric-tested) output from JackalopeGPT.\n\n\n\n“Good” looks like\n\nSpecific, actionable revisions\nClearly prioritized and realistic\nDemonstrates mature judgment about improving inference and communication",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Assignments & Grades</span>"
    ]
  },
  {
    "objectID": "chapters/assignment_grades.html#general-assignment-submission-requirements",
    "href": "chapters/assignment_grades.html#general-assignment-submission-requirements",
    "title": "Assignments & Grades",
    "section": "General assignment submission requirements",
    "text": "General assignment submission requirements\nFor all assignments, a template is provided. Each template is formatted using Quarto Markdown, which is preferred to R Markdown. While R Markdown is not obsolete by any means, it has a number of disadvantages compared to Quarto; these are summarized in the table below.\n\n\n\nDimension\nR Markdown\nQuarto\n\n\n\n\nage\nolder\nnewer\n\n\nprimary language\nR\nmulti-language\n\n\ndocument types\nreports\ndocs, books, sites, slides\n\n\ncross-referencing\nmanual\nbuilt-in\n\n\nextensibility\nconstrained\nmodular\n\n\n\nSo, in your own work, if you ever anticipate wanting to streamline your workflow, I recommend migrating your old R Markdown files to Quarto. Note that there are a few steps to do so, steps that involve changing file headers and syntax. I have had to do this with my older R Markdown files, and it doesn’t take much time. Quarto can really add huge advantages, including reproducible creation of scientific presentations (sometimes in minutes and not hours).\nFor this course, please use Quarto.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Assignments & Grades</span>"
    ]
  },
  {
    "objectID": "chapters/assignment_grades.html#grading",
    "href": "chapters/assignment_grades.html#grading",
    "title": "Assignments & Grades",
    "section": "Grading",
    "text": "Grading\n\n\nNumerical grades are downright loathsome. For all assignments, I use the Traffic Signal Grading Scale:\n\n\n\n\n\n\n\n\nGrade\nSimple meaning\nScientific judgement\n\n\n\n\nGreen\nGood to Proceed\nScientifically coherent for this milestone\n\n\nYellow\nExercise Caution\nViable, but revision is required\n\n\nRed\nStop and Rework\nNot yet ready for scientific judgment\n\n\n\nYellow is not bad. It just means there are certain elements that you should tighten up before moving on. Red is also not bad. It just means there are more elements that you should tighten up before moving on. Hmm…see a pattern here? Maybe top-tier science is built upon iterative improvements?",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Assignments & Grades</span>"
    ]
  },
  {
    "objectID": "chapters/assignment_grades.html#universal-milestone-grading-rubric",
    "href": "chapters/assignment_grades.html#universal-milestone-grading-rubric",
    "title": "Assignments & Grades",
    "section": "Universal Milestone Grading Rubric",
    "text": "Universal Milestone Grading Rubric\nThe Traffic Signal Grading Scale applies to all Milestone Assignments. Grading reflects scientific readiness relative to the purpose of the milestone.\n\n\n\n\n\n\n\n\n\nDimension\n🟢 GREEN: Good to Proceed\n🟡 YELLOW: Exercise Caution\n🔴 RED: Stop and Rework\n\n\n\n\nPurpose & intent\nClearly meets the core intent of the milestone\nPartially meets intent; key elements need revision\nDoes not meet the core intent of the milestone\n\n\nQuestion or objective\nClear, focused, and appropriate for this stage\nPresent but vague, drifting, or overly broad\nUnclear, unfocused, or missing\n\n\nAlignment (question–data–methods)\nQuestion, data, and approach are coherently aligned\nPartial alignment; gaps or weak links remain\nFundamental mismatch between components\n\n\nReasoning & assumptions\nReasoning is coherent; assumptions or limitations acknowledged\nReasoning incomplete or assumptions implicit\nReasoning unclear or unsupported\n\n\nClaims & language\nClaims are appropriate for the stage of analysis\nSome overreach or ambiguous language\nClaims exceed what the work can support\n\n\nCourse GPT self-check\nUsed appropriately; issues addressed or justified\nUsed, but issues only partially addressed\nLittle or no meaningful evidence of self-checking\n\n\nScientific readiness\nWork is ready to move to the next stage\nViable but requires targeted revision\nNot yet in a usable scientific state\n\n\n\nThis universal grading scale is meant to help you quickly understand where your work stands, not to highlight small mistakes. My goal here is to make expectations clear, keep grading transparent, and help you focus on doing solid, defensible science –all without unnecessary stress over points or formatting (which we will let GenAI work on for you). The scale’s primary benefits include:\n\nIt is easy to read. The traffic light color scheme (green, yellow, and red) tell you right away whether your work is ready to move forward, needs some fixing, or needs a more substantial rethink (the majority of good scientists’ ideas)\nIt is the same for every assignment. I use this scale for all milestone assignments. Therefore, the standards are predictable for every assignment.\nIt centers on scientific readiness, not scientific perfection (which, technically, does not exist). You are not being graded on having the “right” answer. What matters most to me is whether your question, data, and reasoning co-exist coherently together.\nIt matches how real science works. Research almost never gets it right on the first try; drafts, checks, and revisions are normal.\nIt allows for rapid feedback. GenAI will do some of the busy work associated with troubleshooting coding issues or improving clarity, which will give me more time to gauge the scientific readiness of your work. A win-win for us all!",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Assignments & Grades</span>"
    ]
  },
  {
    "objectID": "chapters/project_scoping.html",
    "href": "chapters/project_scoping.html",
    "title": "Project Scoping",
    "section": "",
    "text": "The big idea: pick a data analysis project that benefits from the course topics\nThis course is designed so that your final product (Methods + Results + start of Discussion / primary inferences) is built incrementally across Milestone Assignments. The fastest way to struggle in this course is to choose a project that is “interesting” but not workable (either because it is too big, or it is beyond your current experience level). The fastest way to thrive is to choose a project that is both meaningful to you and also has a clearly defined scope.\nBelow are a few concrete recommendations for scoping a project that is:\nEvery milestone is a checkpoint that asks you to refine the same project:\nA well-scoped project means each milestone feels like a natural next step, not a complete and uncomfortable reset.\nBelow are five Principles of Scoping for projects in this course (click on the boxes to expand):",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Project Scoping</span>"
    ]
  },
  {
    "objectID": "chapters/project_scoping.html#the-big-idea-pick-a-data-analysis-project-that-benefits-from-the-course-topics",
    "href": "chapters/project_scoping.html#the-big-idea-pick-a-data-analysis-project-that-benefits-from-the-course-topics",
    "title": "Project Scoping",
    "section": "",
    "text": "Week 2: Analysis Concept Note (scope + design clarity + workflow plan)\nWeek 4: Data Readiness Note (data trustworthiness + Exploratory Data Analysis with purpose)\nWeek 7–8: Working Model (runnable → defensible → locked)\nWeek 12: Interpretation Memo (uncertainty-aware reasoning)\nWeek 14: Results Section (clear, concise quantitative reporting)\nWeek 15: Full Draft (coherent paper-like product)\nWeek 16: Revision Plan (strategic improvement thinking)\n\n\n\n\n\n\n\n\n\nTipScoping Principle #1: “You only get one semester of attention”\n\n\n\n\n\nChoose a question that you will be happy thinking about repeatedly but only for this finite, semester-long period. If the project is too small, there is a danger that you may become bored. If the project is too big and ambitious, you will likely drown in a turbulent sea of discontent (and then blame me or your housemate).\nA good scope has:\n\nOne central question (plain language; 1–3 sentences)\nOne primary response variable (or a tightly related pair)\nA manageable predictor set (start small; justify later additions)\nA clear unit of analysis (what is one “row,” conceptually?)\nA realistic path to one defensible model by Week 8\n\n\n\n\n\n\n\n\n\n\nTipScoping Principle #2: “Your project should teach you the course”\n\n\n\n\n\nThis course covers:\n\nMetrology, uncertainty, and data quality\nExploratory Data Analysis for messy data\nGLMs → GLMMs → GAMs / GAMMs\nSpatial / temporal heterogeneity\nModel comparison (AIC)\nPrediction and validation\nStructural causal modeling (conceptual level; DAGs)\nWriting results with restraint (defensible claims)\n\nA strong project doesn’t need to use every tool — but it should naturally connect to several of them. Ideally, your project has at least one “real” complication that forces you to think like a scientist:\n\nnon-independence (repeated measures; clustered sampling)\nzeros (many true zeros or detection problems)\nunequal effort / detectability issues\nseasonality or temporal structure\nspatial clustering / site heterogeneity\nmeasurement uncertainty or instrument drift\n\n\n\n\n\n\n\n\n\n\nTipScoping Principle #3: Use this to build an reusable infrastructure\n\n\n\n\n\nThe biggest hidden benefit of a good scope is that it rewards you for building a clean workflow early:\n\nclear folder structure\nreproducible Quarto document(s)\na lightweight data dictionary\nstable variable names and units\nAI interaction logging for troubleshooting and drift tracking\n\nIf your project is well-scoped, each improvement you make in Week 2–4 pays dividends in Weeks 7–15.\n\n\n\n\n\n\n\n\n\nTipScoping Principle #4: pick something that advances your degree\n\n\n\n\n\nIf possible, choose a dataset that:\n\nis from your lab, thesis, dissertation, or a collaborator\nconnects to a real paper/report you could write\nhas a real audience beyond this course (advisor, lab group, agency, etc.)\n\nEven if the final product is “only” a course draft, you want it to be a useful artifact you can revise later.\n\n\n\n\n\n\n\n\n\nTipScoping Principle #5: be honest about what you have right now\n\n\n\n\n\nA project is not “good” because it is fascinating; it is good because you can answer something with the data you actually possess.\nBefore committing, you should be able to answer:\n\nDo I have the dataset in-hand by Week 2?\nDoes the dataset need cleaning, and can this be done by Weeks 2-3?\nAre the key variables already measured?\nCan I explain each variable’s meaning and units by Week 4?\nIs the sampling design understandable enough to model by Week 7?\nCan I reasonably lock a core model by Week 8?\n\nIf the answer is no to any of these, you can still proceed, but you must scope down to what is truly feasible.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Project Scoping</span>"
    ]
  },
  {
    "objectID": "chapters/project_scoping.html#a-practical-scoping-checklist",
    "href": "chapters/project_scoping.html#a-practical-scoping-checklist",
    "title": "Project Scoping",
    "section": "A practical scoping checklist",
    "text": "A practical scoping checklist\nChoose a project that meets most of these (given your current knowledge):\n\nOne question: you can state clearly in plain language\n\nOne primary response: that matches the question\n\nA known sampling structure: (site / individual / time / observer, etc.)\n\nA plausible model family: (GLM / GLMM / GAM / GAMM) you can defend\n\nOne major complication: you can address explicitly (zeros, clustering, etc.)\n\nA results story you can tell honestly: without over-claiming\n\nA dataset you can understand and trust: enough to write Methods",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Project Scoping</span>"
    ]
  },
  {
    "objectID": "chapters/project_scoping.html#examples-of-good-vs.-bad-scope",
    "href": "chapters/project_scoping.html#examples-of-good-vs.-bad-scope",
    "title": "Project Scoping",
    "section": "Examples of good vs. bad scope",
    "text": "Examples of good vs. bad scope\nBelow are examples you can use as patterns. These are collapsed so you can skim quickly.\n\n\n\n\n\n\n\n\nNoteGood scope example (light green)\n\n\n\n\n\nProject title (working):\nCanopy structure and bird counts in repeated point counts\nCentral question (plain language):\nDoes canopy cover predict bird counts per visit, after accounting for site-to-site variation?\nData/design clarity:\n- 30 sites, 4 visits per site\n- Response: count per visit\n- Predictors: canopy cover, wind, observer\n- Grouping: site (random intercept)\nComplication (one is enough):\n- detection likely declines with canopy and wind\n- repeated measures → non-independence\nWhy this is well-scoped:\n- runnable GLMM by Week 7\n- lockable model by Week 8\n- meaningful uncertainty-aware interpretation by Week 12\n- produces a clean Results section by Week 14\nWhat you don’t try to do:\n- no “global biodiversity mechanisms”\n- no causal claims without design support\n- no multi-species hierarchy unless truly necessary\n\n\n\n\n\n\n\n\n\n\n\n\nNoteBad scope example (light red)\n\n\n\n\n\nProject title (vague):\nWhat drives biodiversity in tropical forests?\nCentral question (problem):\nToo broad to be answerable in one semester\nData/design issues:\n- response variable not defined\n- sampling design unclear (“multiple sites and years”)\n- predictors not specified\n- unit of analysis unknown (plot? site? species? time?)\nComplications (too many, unbounded):\n- spatial structure + temporal trends + detection + species turnover\n- multiple outcomes (richness + abundance + composition + traits)\nWhy this scope probably fails:\n- you cannot write Methods early\n- Week 4 becomes endless data wrangling\n- Week 7 has no runnable model (or 10 models with no rubric)\n- Week 8 “lock” is impossible\n- Results become unfocused and hard to defend\nWhat this needs to become viable:\n- choose one response, one scale, one question, and one model family",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Project Scoping</span>"
    ]
  },
  {
    "objectID": "chapters/project_scoping.html#scope-down-moves-that-work-and-feel-good",
    "href": "chapters/project_scoping.html#scope-down-moves-that-work-and-feel-good",
    "title": "Project Scoping",
    "section": "“Scope down” moves that work (and feel good)",
    "text": "“Scope down” moves that work (and feel good)\nIf your idea is too big, these moves are almost always helpful (but we can talk about what is best for your particular goals):\n\nPick one response variable (one outcome, not five)\nChoose one spatial scale (plots or sites, not a whole hierarchy)\nChoose one time window (e.g., one season or one year)\nStart with one model family (GLMM or GAMM — justify later)\nLimit the predictor set to a small set you can defend\nTreat extra complexity as a sensitivity check, not the core project",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Project Scoping</span>"
    ]
  },
  {
    "objectID": "chapters/project_scoping.html#a-final-recommendation-choose-the-project-youll-revisit-after-the-course",
    "href": "chapters/project_scoping.html#a-final-recommendation-choose-the-project-youll-revisit-after-the-course",
    "title": "Project Scoping",
    "section": "A final recommendation: choose the project you’ll revisit after the course",
    "text": "A final recommendation: choose the project you’ll revisit after the course\nPick something you would be proud to show:\n\nyour advisor\nyour lab group\na collaborator\na future committee member\nyour future self\n\nIf you choose well, ZOO/ECOL-5500 will not simply teach methods; it will produce a real, useful product that helps you in the future.",
    "crumbs": [
      "Course Overview",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Project Scoping</span>"
    ]
  },
  {
    "objectID": "chapters/ai_prompting.html",
    "href": "chapters/ai_prompting.html",
    "title": "9  AI Prompting for Analysis",
    "section": "",
    "text": "9.1 Overview\nThis page covers the basics of Large Language Models (LLM), the fundamentals of good prompt engineering and design, and the specifics of how to interact with the JackalopeGPT, the custom GPT for this course.",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>AI Prompting for Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/ai_prompting.html#overview",
    "href": "chapters/ai_prompting.html#overview",
    "title": "9  AI Prompting for Analysis",
    "section": "",
    "text": "9.1.1 What are Large Language Models (e.g. ChatGPT, Gemini, Claude)\nJackalopeGPT is a customized GPT assistant tailored specifically for this course using OpenAI’s ChatGPT, a Large Language Model (LLM). Large Language Models (LLMs) like ChatGPT are advanced generative artifical intelligence systems trained on absolutely massive collections of text, enabling them to answer complex questions, summarize information, write in particular styles, and interact using natural language. Large Language Models are trained in two distinct steps that intentionally put humans in the loop:\n\nSupervised fine-tuning (SFT) teaches the model what to say by training on human-written input–output examples.\nReinforcement learning from human feedback (RLHF) teaches the model how to say it by rewarding outputs people judge as better (clearer, safer, more helpful, etc.).\n\nThe key takeaway is very practical for our purposes in this course: these models are optimized for interaction (between the user and LLM). The trade-off is that they are not necessarily built for accuracy. Model responses to users’ prompts (see Section 8.1.2) can sound amazingly confident and authoritative even when their information is grossly incorrect.\n\n\n9.1.2 What are prompts?\nAs stated above, you begin each interaction with an LLM using a prompt. A prompt is simply your input to the trained model; it is your question or request. There are two broad classes of prompts that are operationally differentiated by their purpose:\n\nEvaluative prompts: Models that produce content (e.g., text, code, summaries, or ideas).\nGenerative prompts: Models that assess or critique ingested data.\n\nIn this course, your goal for JackalopeGPT is not to “get an answer,” so we primarily use evaluative prompts. This prompting type keeps you in control of important scientific decisions and constrains the model’s role to that of a friendly reviewer or sounding board (rather than an autonomous data scientist).\n\n\n\n\n\n\nNoteGood prompt engineering takes practice\n\n\n\nPlease note that it may take a bit of practice to concisely write prompts that contain all of this information and yield high-quality responses, but this is a good framework to get you started.",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>AI Prompting for Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/ai_prompting.html#engineering-successful-prompts",
    "href": "chapters/ai_prompting.html#engineering-successful-prompts",
    "title": "9  AI Prompting for Analysis",
    "section": "9.2 Engineering Successful Prompts",
    "text": "9.2 Engineering Successful Prompts\n\n9.2.1 The iterative prompting loop\nSuccessful prompting is usually iterative, involving the following basic steps:\n\nState expectations clearly. Your goal is to produce an output you can evaluate.\nEvaluate the response using a documented rubric. You should always have an implicit (or explicit) rubric in mind: a short set of criteria that defines what a good response should contain.\nRevise the prompt to reduce ambiguity and increase verifiability. Use the rubric to improve the prompt by clarifying the task/topic/context, adding constraints, and requiring formal checks so the response is easier to evaluate.\nRepeat (briefly, yet thoughtfully). until the output is actionable.\n\n\n\n9.2.2 Why good prompting matters (and why you should verify outputs)\nLarge Language Models can be extremely helpful, but they are not a scientific authority, and its responses are not “timeless.” That is, the quality of the responses depends heavily on what you ask and when you ask it (given what information has been recently folded into the LLM training).\n\n\n9.2.3 Actions for writing strong prompts\n\nLeverage your expertise: Use your biological knowledge to define what matters: structure of your study design, sources of bias (detectability of individuals), confounding variables, scale, or non-independence.\nBe challenging and specific. Remove the escape routes. Provide the response type, design, predictors, and what you want back (models, diagnostics, interpretation template).\nUse explicit constraints: Tell it how to answer (format, scope, evidence requirements), not just what to answer.\nForce juggling: Require it to handle multiple issues at once (e.g., zero inflation + nesting + spatial clustering).\nKeep it realistic: Ask for defensible inference, not magic. Explicitly ask it to flag overreach.\nMake prompts reusable: Favor principles and reasoning over tool/version-specific instructions (unless needed).\nMake prompts unambiguous and evaluable: Avoid “this/that/the above” references that only make sense outside the current chat.\nAvoid broad prompts; make outputs verifiable. Interaction GPTs love to spread their wings when given some wiggle room.\nWrite original prompts. Writing original prompts grounds the model in how you think about a scientific question. The model can help refine language or suggest options, but it should not invent the prompt’s goals.\n\n\n\n\n9.2.4 TRACE: a framework for writing strong prompts\nUse TRACE as a memory hook (technically, a acronymic mnemonic) for what to include in high-quality, repeatable prompts:\n\nT (Task/Topic, aka Context): What problem are you working on? What’s the data/design?\nR (Role): What kind of helper should JackalopeGPT be?\nA (Audience): What level should it explain to?\nC (Criteria): What must a good answer include?\nE (Exclusions): What should it avoid? What is out-of-scope?\n\nHere is a more detailed description. The bracketed, italicized components indicate places where you enter your original prompt components. Examples are given in the Description column.\n\n\n\n\n\n\n\n\n\nLetter\nComponent\nDescription\n\n\n\n\nT\nTask / Topic\nI am working on: [system + response + sampling design + sample sizes]. Known issues: [zeros / detectability / spatial clustering / non-independence / confounding].   Example: I have repeated point counts at 30 sites (4 visits per site). The response variable is bird counts per visit. Predictors include canopy density, wind, and observer. I expect detection of individuals to decline as a function of canopy density and wind.\n\n\nR\nRole\nAct as a [R tutor / methods advisor / model debugger].   Example: Act as an ecology methods advisor and R tutor.\n\n\nA\nAudience\nExplain to a [specified knowledge level].   Example: Explain to a 1st–2nd year ecology graduate student with basic statistics knowledge, who has 5–6 months’ experience working with Generalized Linear Models (GLMs) in R.\n\n\nC\nCriteria\nA good answer must include: [(1) restate the design, (2) assumptions, (3) 2–3 candidate approaches, (4) diagnostics and checks, (5) interpretation limits and what would change the recommendation.]   Example: Propose two scientifically defensible modeling approaches. For each, state assumptions, specify the model structure (in words or formula), list at least two scientifically defensible model diagnostics, and explain what result would be misleading if detection bias is not accounted for.\n\n\nE\nExclusions\nDo not: [write my full assignment / invent data / claim causality / skip assumptions / provide code if concepts only were requested].   Example: Do not claim causal effects. Do not invent data. Do not write end-to-end analysis code. If information is missing, list what is needed rather than guessing.\n\n\n\n\n\n\n\n\n\n\nTipTRACE templates for your convenience\n\n\n\n\n\nGoogle Sheet template (Read-only; you can copy and paste)\nGoogle Doc template (Read-only; you can copy and paste)",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>AI Prompting for Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/ai_prompting.html#evaluating-llm-output",
    "href": "chapters/ai_prompting.html#evaluating-llm-output",
    "title": "9  AI Prompting for Analysis",
    "section": "9.3 Evaluating LLM Output",
    "text": "9.3 Evaluating LLM Output\n\n9.3.1 The Rubric-Prompt Synergy\nA rubric is your short checklist for what a complete and accurate response must include. Do not skip it or underestimate its utility: LLMs can sound confident while being downright wrong and incomplete. A good rubric –derived from your own expertise– is how you keep yourself in control of the LLM’s behavior.\nThink of your prompt as a cake recipe and the rubric as the taste test. (I am already thinking this analogy isn’t worth its salt.) The cake might look finished and ready to bring to the party, but the rubric if what tells you whether the cake is actually edible. In other words, you and your rubric must:\n\nNOT ask “Is this answer impressive and sounds smart?”\n\nDefinitely ask “Is this answer complete, appropriately constrained, and testable or verifiable?”\n\n\n\n9.3.2 Rubric criteria\nAfter developing and running a conceptually good prompt, you can be satisfied that a response is worth using if it satisfies the following criteria:\n\nGets the problem right\n\nStates its assumptions\n\nExplains its reasoning\n\nShows how to check itself\n\nKnows where it could be wrong\n\nIf any one of these is missing, revise the prompt before revising your analysis. To see details about each of the above criteria, click on the green box below to expand.\n\n\n\n\n\n\nTipDetailed criteria for assessing LLM responses\n\n\n\n\n\n\nDoes it get the problem right?\n\nCheck whether the response correctly restates your system, data, and task.\nLook for invented details or a mischaracterized study design.\nIf this fails, stop and revise the prompt (not your interpretation).\n\n\n\n\nDoes it state its assumptions?\n\nIdentify whether assumptions are explicit (e.g., independence, sampling, detection, distributional form, causal limits).\nMissing or vague assumptions make recommendations hard to evaluate.\nTreat missing assumptions as a prompt failure, not a model error.\n\n\n\n\nDoes it explain its reasoning?\n\nLook for a clear, step-by-step chain from design → model → inference.\nExplanations should justify why recommendations follow from the setup.\nWithout step-by-step reasoning, we cannot evaluate conclusions.\n\n\n\n\nIs it verifiable?\n\nThe response should include at least one diagnostic, stress test, or sensitivity check (which we will discuss later in the course)\nIt should explain how the recommendation could fail or mislead.\nAdvice without checks is not trustworthy.\n\n\n\n\nDoes it know where it could be wrong?\n\nCheck for limits: what cannot be concluded, what would be overreach, what remains uncertain.\nLook for acknowledgment of uncertainty.\nOverconfidence is a severe red flag.\n\n\n\n\n\n\n\n9.3.3 Quantifying Model Drift: Another way to put rubrics to work\nLarge Language Models are updated and adjusted over time. That means the same prompt can yield different answers across weeks or months—sometimes subtly, sometimes dramatically. To stay scientifically grounded, you need a habit of validation, a way to detect when the LLM’s behavior has changed and when outputs should no longer be trusted. Consider the following scenario. Imagine you weigh your study subjects on a scale every morning. A lab jackanape recalibrates the scale every few weeks without telling you. After discovering that this has occurred, would you trust that the measurements are directly comparable across time? However, if your lab protocol included a daily measurement of a standardized set of weights, you could determine exactly when recalibrations were back, and, what’s even better, you could adjust your measurements accordingly. Science would be saved!\n\nA practical –and easy– way to assess “model drift” in your own work\n\nKeep 3–5 benchmark prompts you reuse all semester (e.g., “fit a GLMM with random intercept for site, explain assumptions, propose diagnostics”). Ideally, you should document and store these as metadata, so that the phrase(s) can always be connected to a project and also be easily accessed.\nRe-run the same benchmark prompt occasionally (at a predefined interval or whenever you begin a new interaction or project). Save (copy/paste) the prompt + output into your AI Interaction Log.\nExamine the output for changes in:\n\nwhether it correctly restates the design,\nwhether it flags assumptions and/or constraints,\nwhether it proposes diagnostics that are scientifically defensible,\nwhether it starts inventing details or over-claiming.\n[other criteria that you can think of?]",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>AI Prompting for Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/ai_prompting.html#synthesis-examples-of-improving-prompts",
    "href": "chapters/ai_prompting.html#synthesis-examples-of-improving-prompts",
    "title": "9  AI Prompting for Analysis",
    "section": "9.4 Synthesis: Examples of improving prompts",
    "text": "9.4 Synthesis: Examples of improving prompts\nInstructions to students: Read the excessively broad-scope prompt first. Pause and think:\n\nWhat information is missing (hint: use the TRACE framework)?\nWhat verbiage could be added to fill most or all of those missing components? Then expand the box to see a stronger version (based in the TRACE framework)\n\nRubric tag key (TRACE):\n\n[T] Task/Topic context missing or underspecified\n[R] Role missing\n\n[A] Audience missing\n\n[C] Criteria missing (what a “good” answer must include)\n\n[E] Exclusions missing (scope/safeguards)\n\n\n\n9.4.1 Example 1: Debugging R code\n\n“My model isn’t working. Help.”\n\nThis prompt lacks all components of a useful prompt. This would lead to an overly broad response from the Large Language Model. Before clicking to expand this example, think about ways you could improve this prompt.\n\n\n\n\n\n\nTipClick to reveal a stronger prompt (TRACE)\n\n\n\n\n\nMissing tags: [T] [R] [A] [C] [E]\nRubric tags addressed: [T] [R] [A] [C] [E]\n\nAct as an R debugger. I’m a beginner–intermediate R user. I’m fitting a GLMM for counts with a random intercept for site. Here is my code and the exact error message:. A good answer must: (1) identify the likely cause, (2) show the minimal fix, (3) explain why it failed, (4) suggest one diagnostic check. Do not rewrite my entire analysis—just fix the error and explain.\n\n\n\n\n\n\n\n9.4.2 Example 2: Choosing a model strategy (polished but incomplete)\n\n“I have ecological count data collected over multiple sites and years, and I want to choose an appropriate statistical model that accounts for structure in the data. Can you recommend a suitable modeling approach and explain why?”\n\nThis prompt sounds careful and scientific, but it fails to bound the answer and require checks, inviting a vague or overbroad response. Before clicking to expand this example, think about ways you could improve this prompt.\n\n\n\n\n\n\nTipClick to reveal a stronger prompt (TRACE)\n\n\n\n\n\nMissing tags: [C] [E]\nRubric tags addressed: [T] [R] [A] [C] [E]\n\nAct as an ecology methods advisor. I am a graduate student in ecology with variable experience in statistical modeling. I have count data with many zeros; samples nested in plots within sites; repeated measures over time. Compare 2–3 modeling strategies (e.g., negative binomial GLMM vs zero-inflated vs hurdle), state assumptions, and give diagnostics that would falsify each. Do not claim causality; focus on defensible inference.\n\n\n\n\n\n\n\n9.4.3 Example 3: Interpreting a model result\n\n“How do I interpret this coefficient?”\n\nThis is another example of a prompt that is vague even by the standards of a simple web search. This approach invites a vague response or evil hallucinations by the Large Language Model. Before clicking to expand this example, think about ways you could improve this prompt.\n\n\n\n\n\n\nTipClick to reveal a stronger prompt (TRACE)\n\n\n\n\n\nMissing tags: [T] [R] [A] [C] [E]\nRubric tags addressed: [T] [R] [A] [C] [E]\n\nAct as a statistical interpreter for ecology graduate students. I am a graduate student learning how to interpret fitted models rather than build them. I’m fitting a negative binomial GLMM for bird counts with canopy cover as a predictor and site as a random effect. Explain how to interpret the canopy coefficient on the link scale and response scale, state the assumptions required for this interpretation, and describe one way this interpretation could be misleading. Do not claim causal effects.\n\n\n\n\n\n\n\n9.4.4 Example 4: Checking model assumptions\n\n“I’m using a Poisson mixed-effects model for count data with repeated measurements across sites. Can you explain the assumptions of this model and whether it’s appropriate for my analysis?”\n\nThis prompt is very polished but incomplete as it lacks a set of criteria for which a good answer must include. Adding such criteria helps the model craft a more useful response. Before clicking to expand this example, think about ways you could improve this prompt.\n\n\n\n\n\n\nTipClick to reveal a stronger prompt (TRACE)\n\n\n\n\n\nMissing tags: [C]\nRubric tags addressed: [T] [R] [A] [C] [E]\n\nAct as an ecology methods advisor. I am a graduate student in ecology with limited but growing experience using mixed-effects models. I’m using a Poisson GLMM for count data with repeated measures per site. List the key assumptions, propose 2–3 diagnostics to evaluate them, and explain what pattern in the diagnostics would indicate a serious problem. If information is missing, list what you need rather than guessing.",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>AI Prompting for Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/using_jackalope_gpt.html",
    "href": "chapters/using_jackalope_gpt.html",
    "title": "10  Using JackalopeGPT",
    "section": "",
    "text": "10.1 A Reminder: What is JackalopeGPT?\nJackalopeGPT is a learning assistant designed to support quantitative and methodological reasoning in this course. Its primary purpose is to help you improve scientific rigor and streamline your analytical workflow while allowing you to maintain full responsibility for:\nJackalopeGPT does not assign grades (except for the Traffic-Signal readiness lights), make final evaluative decisions, or fill in missing information. Instead, JackalopeGPT has been customized to emphasize:\nIn other words, JackalopeGPT has been designed to help you think better, not to think less.",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using JackalopeGPT</span>"
    ]
  },
  {
    "objectID": "chapters/using_jackalope_gpt.html#a-reminder-what-is-jackalopegpt",
    "href": "chapters/using_jackalope_gpt.html#a-reminder-what-is-jackalopegpt",
    "title": "10  Using JackalopeGPT",
    "section": "",
    "text": "Reasoning\n\nInterpretation\n\nvalidation\n\nAll final assignment submissions\n\n\n\nExplicit assumptions\nTransparent reasoning\n\nScope control\n\nReproducible workflows",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using JackalopeGPT</span>"
    ]
  },
  {
    "objectID": "chapters/using_jackalope_gpt.html#how-you-can-start-using-it-important",
    "href": "chapters/using_jackalope_gpt.html#how-you-can-start-using-it-important",
    "title": "10  Using JackalopeGPT",
    "section": "10.2 How You Can Start Using It (Important)",
    "text": "10.2 How You Can Start Using It (Important)\nIf you are first using JackalopeGPT to optimize your prompts or evaluate an assignment’s completeness before submission, you should use the Main Menu. However, you do not need to choose anything from the Main Menu to begin. The Main Menu exists only for structured actions (such as readiness checks or AI interaction logging). Most learning happens without it. It is only provided for a bit more convenience. You may simply start prompting JackalopeGPT naturally, as you would with any chat-based GPT.",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using JackalopeGPT</span>"
    ]
  },
  {
    "objectID": "chapters/using_jackalope_gpt.html#operating-modes",
    "href": "chapters/using_jackalope_gpt.html#operating-modes",
    "title": "10  Using JackalopeGPT",
    "section": "10.3 Operating Modes",
    "text": "10.3 Operating Modes\nJackalopeGPT operates in three distinct modes:\n\n10.3.1 Learning & Practice (default)\n\nConcept clarification\n\nCode debugging or refactoring\n\nTranslating between modeling frameworks\n\nMethodological explanations\n\nThis mode is informal, exploratory, and never evaluative.\n\n\n10.3.2 Scientific Readiness Evaluation\n\nStructured, rubric-based checks of specific artifacts\n\nExecuted only when explicitly invoked (via menu or trigger phrases)\n\nUsed to assess whether work appears ready for submission, not to grade on scientific quality.\n\n\n\n10.3.3 AI Interaction Logging (To be launched on Monday, 26-Jan-2026!!)\n\nMinimal documentation of AI assistance\n\nTriggered only by the exact command: log this\n\nDesigned for transparency, not surveillance",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using JackalopeGPT</span>"
    ]
  },
  {
    "objectID": "chapters/using_jackalope_gpt.html#safeguards-and-constraints",
    "href": "chapters/using_jackalope_gpt.html#safeguards-and-constraints",
    "title": "10  Using JackalopeGPT",
    "section": "10.4 Safeguards and Constraints",
    "text": "10.4 Safeguards and Constraints\nJackalopeGPT is intentionally constrained:\n\nNon-evaluative by default (but has the Main Menu to allow evaluation)\nAsks at most one clarifying question at a time\nNever guesses or silently fills gaps\n\nDoes not hallucinate criteria or requirements\nDoes not combine Main Menu actions\nGenerally limits verbosity unless you request detail explicitly\n\nAny evaluation or logging action requires explicit transparency and user consent. As a last note, if you are unsure whether your prompt is appropriate, add this line: “If this prompt is likely to cause me to overreach in inference or bypass learning, suggest a safer, learning-focused version.”",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using JackalopeGPT</span>"
    ]
  },
  {
    "objectID": "chapters/using_jackalope_gpt.html#menu-commands-and-triggers",
    "href": "chapters/using_jackalope_gpt.html#menu-commands-and-triggers",
    "title": "10  Using JackalopeGPT",
    "section": "10.5 Menu Commands and Triggers",
    "text": "10.5 Menu Commands and Triggers\nTyping main menu (or Main Menu) displays all available structured actions (with no analysis). This means that JackalopeGPT has all the course assignments and rubrics uploaded into its working knowledge.\nIf you enter a menu number or a similar matching instruction, JackalopeGPT will:\n\nconfirm the action\n\nexecute the instruction file exactly as specified\n\nCertain phrases (e.g., assignment-check intent or log this) automatically trigger workflows before menu selection.",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using JackalopeGPT</span>"
    ]
  },
  {
    "objectID": "chapters/using_jackalope_gpt.html#traffic-signal-rubric-how-evaluations-work",
    "href": "chapters/using_jackalope_gpt.html#traffic-signal-rubric-how-evaluations-work",
    "title": "10  Using JackalopeGPT",
    "section": "10.6 Traffic-Signal Rubric (How Evaluations Work)",
    "text": "10.6 Traffic-Signal Rubric (How Evaluations Work)\nA universal Traffic-Signal rubric is pre-loaded and applied consistently across all readiness checks.\nEvaluations return the follwing ratings of scientific readiness:\n\nGreen: Ready to proceed\n\nYellow: Exercise caution (revisions necessary)\n\nRed: Stop and Rework\n\nThis rubric provides standardized, comparable feedback without grading.",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using JackalopeGPT</span>"
    ]
  },
  {
    "objectID": "chapters/using_jackalope_gpt.html#how-to-generate-an-evaluation-table-required-for-assignments",
    "href": "chapters/using_jackalope_gpt.html#how-to-generate-an-evaluation-table-required-for-assignments",
    "title": "10  Using JackalopeGPT",
    "section": "10.7 How to Generate an Evaluation Table (Required for Assignments)",
    "text": "10.7 How to Generate an Evaluation Table (Required for Assignments)\nBefore submission, you must evaluate assignments using JackalopeGPT.\nSteps:\n\nSelect the focal assignment from the JackalopeGPT menu\n\nCopy and paste the your completed .qmd file (not rendered output)\n\nUse the model output to revise your file until it meets the assignment standard\n\nPaste the complete Evaluation Table output directly from the JackalopeGPT windo (it is already in .qmd format) into the section at the end of each assignment titled JackalopeGPT Pre-Submission Evaluation.\n\n(Tip: hover over the table until the file icon appears at the upper right, then copy.)",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using JackalopeGPT</span>"
    ]
  },
  {
    "objectID": "chapters/using_jackalope_gpt.html#important-usage-notes",
    "href": "chapters/using_jackalope_gpt.html#important-usage-notes",
    "title": "10  Using JackalopeGPT",
    "section": "10.8 Important Usage Notes",
    "text": "10.8 Important Usage Notes\n\n10.8.1 Interaction Limits\nIf you are using the free tier (recommended), be aware of interaction limits. Plan longer evaluation workflows accordingly.\n\n\n10.8.2 Memory and Sessions\nJackalopeGPT does not retain memory across sessions.\nIf you start a new session, you must re-provide context about:\n\nyour study system\n\nyour data\n\nyour analytical goals\n\nDo not assume continuity across chats. It is strongly recommended that you keep a file with your updated and optimized prompts so that you can reuse.",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using JackalopeGPT</span>"
    ]
  },
  {
    "objectID": "chapters/using_jackalope_gpt.html#a-reminder-about-the-appropriate-use-in-this-course",
    "href": "chapters/using_jackalope_gpt.html#a-reminder-about-the-appropriate-use-in-this-course",
    "title": "10  Using JackalopeGPT",
    "section": "10.9 A reminder about the appropriate use in this course",
    "text": "10.9 A reminder about the appropriate use in this course\n\n10.9.1 You may use JackalopeGPT to:\n\nclarify concepts\n\ndebug R code\n\ncompare modeling approaches (with explanation)\n\nlearn how to validate models\n\nimprove analytical workflow and reproducibility\n\n\n\n10.9.2 You may not use JackalopeGPT to:\n\ngenerate full assignment submissions\n\nwrite end-to-end analyses, methods, or results\n\nreplace your own reasoning\n\noutsource scientific judgment\n\nproduce claims without validation",
    "crumbs": [
      "Part ∅: AI preparation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using JackalopeGPT</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_workflow_intro.html",
    "href": "chapters/reproducible_workflow_intro.html",
    "title": "11  Reproducible Analyses",
    "section": "",
    "text": "11.1 Why start with reproducible analysis workflows?\nAlthough ZOO/ECOL-5500 focuses on quantitative analysis and modeling, those tools are only as reliable as the infrastructure that supports them. Establishing a clear, reproducible workflow creates a solid foundation that can scale appropriately as new data arrive –whether that means new sensor downloads, ongoing field observations, or ever-expanding datasets– without requiring you to constantly restructure, reinvent, or debug your analysis.\nThis chapter provides the broad conceptual map for the rest of Part I. Subsequent chapters focus on individual components of this workflow.\nEverything up to (and including) production of figures and tables can and should be reproducible. That is, (1) you should be able to rerun an entire analysis and produce tables and figures (and fill in values in a Results section) with a simple click of a button, and (2) another user should be able to reproduce all steps in your analysis pipeline, even with minimal code. Framing the workflow as a casual path makes obvious how each result is causally linked to specific inputs, transformations, and assumptions.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducible Analyses</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_workflow_intro.html#what-is-a-reproducible-analytical-workflow",
    "href": "chapters/reproducible_workflow_intro.html#what-is-a-reproducible-analytical-workflow",
    "title": "11  Reproducible Analyses",
    "section": "11.2 What is a reproducible analytical workflow?",
    "text": "11.2 What is a reproducible analytical workflow?\nA common misconception—especially early in graduate training—is that reproducibility means sharing files and code on GitHub, Dryad, or similar repositories. Those components are necessary, but they is not sufficient.\nA reproducible analytical workflow is a structured system that explicitly and completely describes how scientific results are generated. Such a workflow:\n\nstarts with observations of the world, not the computer\ntreats measurement as a translation (or signal-transduction) process\nclearly and explicitly documents where data come from\nseparates data, metadata, processing, and inference\nrecords inputs → transformations → outputs at each step (this is key!)\nmakes explicit where assumptions or biases are introduced\nallows another person (or you, six months later) to reconstruct the results\n\nTogether, these features ensure that analyses can be understood, repeated, extended, and scaled as new data arrive.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducible Analyses</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_workflow_intro.html#the-reproducible-analytical-workflow-as-a-causal-system",
    "href": "chapters/reproducible_workflow_intro.html#the-reproducible-analytical-workflow-as-a-causal-system",
    "title": "11  Reproducible Analyses",
    "section": "11.3 The reproducible analytical workflow as a causal system",
    "text": "11.3 The reproducible analytical workflow as a causal system\nThe reproducible analytical workflow can be understood as a causal system in which each step produces downstream consequences: measurement choices shape the raw data, data processing constrains what can be modeled, and modeling assumptions determine what can be inferred. Thinking causally about the workflow makes it clear that results do not simply “come from the data,” but from a chain of decisions that can be traced, tested, and reproduced. Generally, this pipeline looks like this:\n\nWorld → Data → Models → Inference → Interpretation\n\nMore explicitly, as seen in the diagram at right, we have the following general steps:\n\nWorld / phenomena: Processes exist whether or not we observe them (or like them!)\nMeasurement & observation: Instruments and observers translate phenomena into recorded values.\nRaw data + metadata: Raw data must have metadata as context.\nProcessing & derivation: Filtering, organizing, feature extraction, etc.\nModels & inference rules: Assumptions can be documented and coded explicitly.\nInterpretation: Human judgment (which is usually not reproducible, unless codified).",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducible Analyses</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_workflow_intro.html#why-workflows-matter-scientifically",
    "href": "chapters/reproducible_workflow_intro.html#why-workflows-matter-scientifically",
    "title": "11  Reproducible Analyses",
    "section": "11.4 Why workflows matter scientifically",
    "text": "11.4 Why workflows matter scientifically\nReproducibility in a scientific workflow is not primarily about convenience, though it often becomes convenient over time. A convenient –but non-reproducible– workflow focuses on rerunning an analysis quickly, often relying on memory, manual steps, and undocumented choices. That approach may work in the short term, but it does not scale and rarely holds up weeks, months, or years later. A reproducible workflow, by contrast, is designed so that every result can be traced back to its origins, including the data, code, assumptions, and decisions that produced it.\nAt a broader scale, reproducible workflows allow us to:\n\ndiagnose errors\nunderstand sensitivity to assumptions\nreuse data responsibly\nbuild on previous work without re-guessing decisions\nreduce long-term computational and cognitive overhead\n\nIn short:\n\nConvenience: “Can I run this analysis again?”\nReproducibility: “Can I clearly show how these results were produced?”",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducible Analyses</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_workflow_intro.html#how-part-i-reproducible-analyses-is-organized",
    "href": "chapters/reproducible_workflow_intro.html#how-part-i-reproducible-analyses-is-organized",
    "title": "11  Reproducible Analyses",
    "section": "11.5 How Part I: Reproducible Analyses is organized",
    "text": "11.5 How Part I: Reproducible Analyses is organized\nThis Part follows the workflow in stages:\n\nNature of data: What data are, how measurement works, and what raw data means.\nMetadata (low friction): How to document context without drowning in formatting standards.\nReproducible workflows: Why multiple step-by-step scripts are not enough; the need for explicit input–output mapping.\nInference and interpretation: Where assumptions enter and where reproducibility ends.\n\nEach chapter is responsible for a specific region of the workflow.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducible Analyses</span>"
    ]
  },
  {
    "objectID": "chapters/reproducible_workflow_intro.html#a-guiding-principle",
    "href": "chapters/reproducible_workflow_intro.html#a-guiding-principle",
    "title": "11  Reproducible Analyses",
    "section": "11.6 A guiding principle",
    "text": "11.6 A guiding principle\n\nIf you cannot say what a result depends on, it is not reproducible.\n\nKeep this sentence in mind as you move forward. The next chapter starts where all workflows begin: with the nature of data themselves.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Reproducible Analyses</span>"
    ]
  },
  {
    "objectID": "chapters/nature_of_data.html",
    "href": "chapters/nature_of_data.html",
    "title": "12  The Nature of Data",
    "section": "",
    "text": "12.1 Introduction\nUnderstanding the nature of your data is the first real step toward defensible ecological inference.You were asked to come into this course with a dataset in hand. Some of you have undoubtedly arrived with very well-organized spreadsheets. Others have long lists of folders full of raw sensor outputs, GIS layers, audio files, camera-trap images, or field notes that only you can currently interpret. All of that is perfect for this course.\nBefore we analyze anything, however, we need to be precise about three things:\nMost scientific confusion comes from mixing these three up. If you do not understand these three critical components, no amount of fancy R coding will save your analysis.\nSo, we begin where all data originate: measurement. And, for that, it helps to start with a brief introduction to the field of metrology.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Nature of Data</span>"
    ]
  },
  {
    "objectID": "chapters/nature_of_data.html#introduction",
    "href": "chapters/nature_of_data.html#introduction",
    "title": "12  The Nature of Data",
    "section": "",
    "text": "What measurements represent\n\nWhat data are\n\nWhat we are actually trying to estimate",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Nature of Data</span>"
    ]
  },
  {
    "objectID": "chapters/nature_of_data.html#metrological-terminology",
    "href": "chapters/nature_of_data.html#metrological-terminology",
    "title": "12  The Nature of Data",
    "section": "12.2 Metrological Terminology",
    "text": "12.2 Metrological Terminology\nMetrology is simply the science of measurement. Whereas it has traditionally focused on the physical sciences and engineered systems, it applies just as much to biology and its messier subfields (e.g. ecology) as it does to physics or chemistry.\nMetrology establishes a formal framework for ensuring that scientific measurements are traceable to standards, reported with uncertainty, and reproducible across space, time, and observers. Crucially, this framework operates upstream of analysis—at the moment when information about the world are collected an raw data are generated. Metrology naturally integrates with our discussion of reproducible analyses because, instead of a number standing alone, a measurement comes bundled with information about what it was trying to measure, how reliable it is, and what assumptions were made along the way. That lets future researchers decide whether datasets are truly comparable, whether old data can answer new and exciting questions, and how much trust researchers should place in a result without having to guess what the original researcher meant.\nTwo term must be clearly differentiated from measurements and estimates. These terms are:\n\nmeasurand\nestimand\n\n\n\n\n\n\n\nNoteEtymology of measurand and estimand\n\n\n\n\n\nThe suffix –and comes from Latin –andus\n(“that which is to be acted upon [a target]”)\n\n\n\nTarget (–and)\nResult\n\n\n\n\nMeasurand\nMeasurement\n\n\nEstimand\nEstimate\n\n\n\n\n\n\n\n\n\n12.2.1 Measurand!\n\nThe theoretical quantity of interest in the world to be measured.\n\nA measurand:\n\nexists independently of observers\n\nis defined conceptually, not instrumentally\n\nis the quantity you wish you could measure directly\n\nExamples:\n\ntrue wing length\n\nactual activity level\n\nreal population abundance\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe measurand is defined before measurement and never directly observed.\n\n\n\n\n\n\n\n\n\n\nNoteCan we ever directly achieve the measurand?\n\n\n\nShort answer: Almost never—and that is normal science.\n\n\n\n\n\n\n12.2.2 Estimand! (the missing precision tool)\n\nThe quantity that a statistical model is designed to estimate, given the available data.\n\nThough we will discuss estimands at length later in the course during the modeling exercises, it helps to discuss it in the context of measurands. An estimand:\n\nis defined by both the scientific question and the analysis model\n\ndepends on the data, measurement process, and assumptions\n\nis the quantity you can actually estimate from the data\n\nExamples:\n\nmean wing length in the sampled population\n\nexpected activity level given detection and sampling design\n\nestimated population abundance under a specified model\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe estimand is defined before analysis, depends on modeling choices, and is not the same as the measurand.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Nature of Data</span>"
    ]
  },
  {
    "objectID": "chapters/nature_of_data.html#summary-measurand-vs-estimand",
    "href": "chapters/nature_of_data.html#summary-measurand-vs-estimand",
    "title": "12  The Nature of Data",
    "section": "12.3 Summary: Measurand vs Estimand",
    "text": "12.3 Summary: Measurand vs Estimand\n\n\n\nConcept\nMeasurand\nEstimand\n\n\n\n\nNature\nConceptual / scientific\nFormal / statistical\n\n\nExists without data?\nYes\nNo\n\n\nDepends on model?\nNo\nYes\n\n\nDefined when?\nBefore measurement\nBefore estimation\n\n\n\n\n\n\n\n\n\n\nNoteWhere does each concept belong in a scientific paper?\n\n\n\n\n\n\n\n\nConcept\nSection\n\n\n\n\nMeasurand\nIntroduction\n\n\nEstimand\nMethods\n\n\nEstimate\nResults\n\n\nInterpretation (circling back to measurand)\nDiscussion",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Nature of Data</span>"
    ]
  },
  {
    "objectID": "chapters/nature_of_data.html#what-are-data",
    "href": "chapters/nature_of_data.html#what-are-data",
    "title": "12  The Nature of Data",
    "section": "12.4 What are data?",
    "text": "12.4 What are data?\nOnly after measurement do we get data, the recorded outputs of those measurement processes. To understand what is meant by data, let us consult a dictionary first. Two definitions from the Merriam-Webster Dictionary—188 years apart—are especially revealing:\n\n\n\n\n\n\n\n\nNoteMerriam-Webster (2016)\n\n\n\n“Facts or information used usually to calculate, analyze, or plan something.”\n\n\n\n\n\n\n\n\n\n\n\nNoteMerriam-Webster (1828)\n\n\n\n“Quantities, principles, or facts given or admitted, by which to find things or results unknown.”\n\n\n\n\nModern usage treats data and information as synonymous. But scientifically, this is misleading.\nData are observed facts. Information is what we extract from those facts using models and assumptions.\nWe do not collect information. We collect data, and then we extract or create information. This distinction is critical for reproducibility.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Nature of Data</span>"
    ]
  },
  {
    "objectID": "chapters/nature_of_data.html#raw-data",
    "href": "chapters/nature_of_data.html#raw-data",
    "title": "12  The Nature of Data",
    "section": "12.5 Raw data",
    "text": "12.5 Raw data\nBecause measurands cannot be observed directly and estimands depend on how data are generated and modeled, raw data are the critical link between scientific questions (filled with measurands) and strong inference. Raw data preserve the closest recorded traces of the measurement process, making it possible to understand how observations relate to the underlying measurand and what estimands the data can actually support.\nBy now, we have all been conducting formal scientific inquiry for many years. It is common to see folders labeled /raw_data/ that contain offloaded sensor files or spreadsheets transcribed from field notebooks. These data may feel “raw,” but often they are not.\n\nRaw data are the facts produced by an instrument or observer through a domain-specific translation, recorded at the time of observation, and preserved without post-hoc modification.\n\n\n\nWhen we offload data from a sensor or transcribe notes into a spreadsheet, our actions have a non-zero probability of influencing the data.\nExamples of raw data include:\n\naudio waveforms recorded at a study site (on the device)\n\nGPS locations logged by a collar (not yet downloaded)\n\ncounts written on a datasheet (not yet transcribed)\n\npixel values collected by a camera sensor\n\n\n\n\n\n\n\n\n\n\n\n\nWarningCommon misconceptions about raw data\n\n\n\n\n\n\nRaw data are not clean, tidy, or analysis-ready\n\nProcessed tables and summaries are not raw data\n\nRaw data are not the truth—they are translated observations\n\nRaw data are not limited to numbers\n\nMessiness does not imply poor data quality\n\nEarly processing choices permanently change the data\n\n\n\n\n\nRaw data are the foundation of all scientific analysis. On their own, however, they are incomplete. To be interpretable, reusable, and reproducible, raw data require context.\nThat context comes from metadata, which are introduced on the next page. Keeping the focus here on raw data helps avoid mixing observations of the world with explanations about how those observations were produced. Metadata play a different conceptual role, and treating them separately keeps that distinction clear.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Nature of Data</span>"
    ]
  },
  {
    "objectID": "chapters/metadata_low_friction.html",
    "href": "chapters/metadata_low_friction.html",
    "title": "13  Metadata",
    "section": "",
    "text": "13.2 Why metadata are essential\nMetadata record the information needed to interpret measurements correctly. They tell us:\nMetadata are not bureaucracy. They are scientific memory. Without metadata, data quickly lose meaning—especially once they leave the hands of the person who collected them.\nRaw data without metadata are often difficult—or impossible—to interpret, even by the original researcher. In practice, many irreproducible analyses fail before modeling begins, because key contextual information was never recorded. A column of numbers without units, provenance, or spatial and temporal context is just a sequence of values. It is not reusable scientific data.\nAt a broad level, good metadata allow others (and future you) to:\nMetadata do not guarantee good science, but their absence almost guarantees future confusion.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Metadata</span>"
    ]
  },
  {
    "objectID": "chapters/metadata_low_friction.html#what-metadata-are-and-are-not",
    "href": "chapters/metadata_low_friction.html#what-metadata-are-and-are-not",
    "title": "13  Metadata",
    "section": "13.1 What metadata are (and are not)",
    "text": "13.1 What metadata are (and are not)\n\nMetadata are data about data.\n\nThis definition is technically correct, but not very useful on its own. A more practical way to think about metadata is this:\n\nMetadata describe the context in which data were generated.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Metadata</span>"
    ]
  },
  {
    "objectID": "chapters/metadata_low_friction.html#why-metadata-are-essential",
    "href": "chapters/metadata_low_friction.html#why-metadata-are-essential",
    "title": "13  Metadata",
    "section": "",
    "text": "understand what the data actually represent, and what their limitations are\n\njudge whether the data are appropriate for a new purpose or analysis\n\nreconstruct and evaluate analytical decisions made downstream",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Metadata</span>"
    ]
  },
  {
    "objectID": "chapters/metadata_low_friction.html#metadata-within-a-reproducible-analytical-workflow",
    "href": "chapters/metadata_low_friction.html#metadata-within-a-reproducible-analytical-workflow",
    "title": "13  Metadata",
    "section": "13.3 Metadata within a reproducible analytical workflow",
    "text": "13.3 Metadata within a reproducible analytical workflow\nReproducibility is not just about being able to rerun code indefinitely. It also requires being able to answer core questions about the data themselves, such as:\n\nWhat exactly was measured?\n\nUnder what conditions were the measurements taken?\n\nWhat instruments or protocols were used?\n\nWhat were the data’s limitations or sources of error?\n\nMetadata provide the necessary bridge between raw data and scientific inference. They explain how measurements came to exist and clarify which kinds of estimands the data can —and cannot— support.\nWithin the broader analytical workflow, raw data and metadata together form a complete dataset. Complete datasets can be verified, versioned, shared, and reused. All subsequent processing, modeling, and inference depend on this foundation.\n\nTo emphasize, metadata are not an afterthought; they are part of the data.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Metadata</span>"
    ]
  },
  {
    "objectID": "chapters/metadata_low_friction.html#what-good-metadata-enable-fair-in-plain-language",
    "href": "chapters/metadata_low_friction.html#what-good-metadata-enable-fair-in-plain-language",
    "title": "13  Metadata",
    "section": "13.4 What good metadata enable (FAIR, in plain language)",
    "text": "13.4 What good metadata enable (FAIR, in plain language)\nAt their core, the FAIR principles (Wilkinson et al. (2016)) recognize that data are only useful if their context travels with them. Metadata are what make this possible. Much of the modern emphasis on metadata comes from the FAIR principles, which aim to ensure that scientific data are:\n\nFindable: Metadata help other people find that the data exist.\nAccessible: Metadata explain how to get the data and what the files mean.\nInteroperable: Metadata make it clear how the data are formatted and measured, so they work with other data.\nReusable: Metadata explain how the data were collected and what their limits are, so others can use them correctly.\n\nCrucially, FAIR is not about ensuring perfection; it is about increasing the probability of future usability.\n\n\n\n\n\n\nNote\n\n\n\nYou are not expected to memorize the FAIR acronym. What matters most is understanding what FAIR is trying to do (specifically, what it is trying to protect)!",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Metadata</span>"
    ]
  },
  {
    "objectID": "chapters/metadata_low_friction.html#a-low-friction-approach-to-metadata",
    "href": "chapters/metadata_low_friction.html#a-low-friction-approach-to-metadata",
    "title": "13  Metadata",
    "section": "13.5 A low-friction approach to metadata",
    "text": "13.5 A low-friction approach to metadata\nYou have probably encountered the long list of formal metadata standards used across scientific disciplines. For this course, you do not need to master any of them, and, in fact, you barely need to know them at all.\nOur approach to metadata is intentionally low friction. That means it fits naturally into you (and others) already work: without extra tools or unnecessary extra steps, and without specialized expertise. The goal is not blind compliance to reporting standards; first and foremost, it is about scientific clarity. We therefore adopt a simple guiding principle:\n\nLet repositories handle standardization. Your job is to record clear, honest, human-readable metadata.\n\nRepositories such as Dataverse, Zenodo, Dryad, GBIF, and institutional archives are designed to translate user-supplied documentation into formal metadata schemas. That translation only works, however, if the essential information about your data exists in the first place. What matters most at this stage is clarity and completeness, not adherence to a specific –and often over-specified– standard.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Metadata</span>"
    ]
  },
  {
    "objectID": "chapters/metadata_low_friction.html#what-good-enough-metadata-must-accomplish",
    "href": "chapters/metadata_low_friction.html#what-good-enough-metadata-must-accomplish",
    "title": "13  Metadata",
    "section": "13.6 What “good enough” metadata must accomplish",
    "text": "13.6 What “good enough” metadata must accomplish\nAt a minimum, metadata should allow another scientifically literate person—someone outside your project—to answer the following questions:\n\nWhat are these data?\n\nWho created them?\n\nWhen and where were they collected?\n\nHow were the measurements made?\n\nWhat files belong together, and how?\n\nIf these questions cannot be answered from the metadata alone, the dataset is not reusable—no matter how sophisticated the analysis or modeling may be.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Metadata</span>"
    ]
  },
  {
    "objectID": "chapters/metadata_low_friction.html#practical-formats-for-early-stage-metadata",
    "href": "chapters/metadata_low_friction.html#practical-formats-for-early-stage-metadata",
    "title": "13  Metadata",
    "section": "13.7 Practical formats for early-stage metadata",
    "text": "13.7 Practical formats for early-stage metadata\nIn everyday research workflows, metadata often begin life in simple, familiar formats such as:\n\nGoogle Sheet (good for coordinating field or lab work)\n\nplain-text or Markdown file (good for small or exploratory projects)\n\nThese formats are perfectly acceptable as starting points. They lower the barrier to documentation and encourage metadata to be written early in the analysis life-cycle rather than postponed. However, these format are usually best treated as temporary representations. As projects grow, metadata need to become more structured, more explicit, and easier to validate and reuse. But, if you are more comfortable beginning your journey using a version-controlled spreadsheet platform (like Google Sheets), you are welcome to do so.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Metadata</span>"
    ]
  },
  {
    "objectID": "chapters/metadata_low_friction.html#why-we-use-yaml",
    "href": "chapters/metadata_low_friction.html#why-we-use-yaml",
    "title": "13  Metadata",
    "section": "13.8 Why we use YAML",
    "text": "13.8 Why we use YAML\nTo support that transition from your mind (or Google Sheets), this course adopts YAML as the canonical format for project-level metadata.\n\n\n\n\n\n\nNoteYAML: What’s in a name?\n\n\n\nOriginally, YAML was an abbreviation for “Yet Another Markup Language”. Later, it become “YAML Ain’t Markup Language”.\n\n\n\n\n\n\n\n\nNoteWhat the heck is canonical in this context?\n\n\n\nCanonical simply means that there is exactly one place where your dataset is formally defined; it does not mean that your metadata exists as exactly one file (thought it could).\n\n\nThere are several advantages to using YAML, including:\n\nhuman-readable and easy to edit\n\nstructured and explicit about relationships\n\neasy to version-control\n\nsimple to validate and extend (i.e. Quarto markdown files have YAML headers)\nstraightforward to convert into repository-specific schemas later\n\nMost importantly, YAML encourages you to think carefully about what varies, what stays constant, and how different pieces of a dataset relate to one another.\nIn the next section, we will walk through the structure of a well-designed YAML metadata file, using concrete examples and expandable templates to show how common research scenarios —such as multiple instruments, deployments, or sampling rates— can be documented clearly and correctly (at least, I hope so).",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Metadata</span>"
    ]
  },
  {
    "objectID": "chapters/metadata_low_friction.html#levels-of-metadata-where-information-belongs-and-where-it-does-not",
    "href": "chapters/metadata_low_friction.html#levels-of-metadata-where-information-belongs-and-where-it-does-not",
    "title": "13  Metadata",
    "section": "13.9 Levels of metadata: where information belongs (and where it does not)",
    "text": "13.9 Levels of metadata: where information belongs (and where it does not)\nWhen you document metadata, your main job is to put information at the right level of scope. This keeps metadata clear, avoids duplication, and prevents the most common failure mode: collapsing variation.\nA useful way to think about this is a hierarchy of levels, from broad context to individual files.\n\n\n\n\n\n\n\nNoteDataset-level metadata (the whole project)\n\n\n\n\n\nThis level answers: What is this data set, broadly, and how should it be cited, discovered, and reused?\nWhat belongs at this level\n\ntitle, description, and keywords\n\ncreators, affiliations, persistent identifiers (e.g., ORCID)\n\noverall spatial and temporal scope (broad bounds, if applicable)\n\nlicense and usage rights\n\nrelated identifiers (publications, code repositories, DOIs)\n\nhigh-level description of how the data were generated\n\nprovenance summary (e.g., “data collection + processing workflow”)\n\nWhat does not belong at this level\n\nfile-specific settings or parameters\n\nvalues that vary across observations or files\n\nderived results (means, medians, model outputs)\n\nvague summaries such as “most values were…”\n\n\n\n\n\n\n\n\n\n\n\nNoteInstrument- or system-level metadata (the measurement system)\n\n\n\n\n\nThis level answers: What system, instrument, or process produced the measurements, and what are its stable properties?\nWhat belongs at this level\n\nsystem or instrument type, manufacturer, and model\n\nserial number, asset ID, or logical identifier\n\nsoftware or firmware version (if relevant)\n\nproperties that are stable across use (e.g., resolution, precision, bit depth)\n\nWhat does not belong at this level\n\nsettings that vary across observations unless explicitly declared as defaults\n\ntime- or location-specific information\n\n\n\n\n\n\n\n\n\n\n\nNoteDeployment- or configuration-level metadata (a consistent setup)\n\n\n\n\n\nThis level answers: When and under what conditions was the system used with a consistent configuration?\nWhat belongs at this level\n\nconfiguration or deployment identifier\n\ncontextual identifiers (e.g., site, batch, experiment, run)\n\nstart and end dates or times\n\nparameters that were constant during this configuration\n\ncalibration notes, protocols, or procedural references\n\nWhat does not belong at this level\n\nindividual file or observation exceptions unless explicitly mapped\n\nvalues that vary within the configuration without structure\n\n\n\n\n\n\n\n\n\n\n\nNoteFile- or observation-level metadata (individual data units)\n\n\n\n\n\nThis level answers: What is true about this specific file, record, or observation?\nWhat belongs at this level\n\nfilename or observation identifier\n\ndate and time of acquisition or creation\n\nparameter values that vary (e.g., sampling rate, resolution, settings)\n\ncontextual attributes that differ across observations\n\nlocation information, if variable\n\nWhat does not belong at this level\n\ndataset-wide descriptions\n\ninterpretive judgments (e.g., “high quality”) unless defined by a controlled scheme\n\n\n\n\n\n\n\n\n\n\n\n\nTipTwo rules that prevent most metadata mistakes\n\n\n\n\n\n\nPlace metadata at the highest level where they are constant.\nIf a sampling rate never changes across a deployment, store it at the deployment or instrument level.\nIf a metadata value varies, do not summarize it; map it explicitly by adding another metadata entry (see Example 3-4 below.\nNever write “sampling_rate_hz: 48000” plus “some files differ.”Instead, record which files have which values.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Metadata</span>"
    ]
  },
  {
    "objectID": "chapters/metadata_low_friction.html#examples-recording-metadata-at-different-levels",
    "href": "chapters/metadata_low_friction.html#examples-recording-metadata-at-different-levels",
    "title": "13  Metadata",
    "section": "13.10 Examples: recording metadata at different levels",
    "text": "13.10 Examples: recording metadata at different levels\nThe examples below illustrate how metadata structure changes depending on what varies in a dataset. Each example shows the same basic information organized at different levels to preserve clarity and traceability. The goal is not to memorize a template, but to understand how scope and variation determine where metadata belong.\nThe following examples illustrate common scenarios using YAML. Each example shows how scope and variation determine where information belongs. Note that the Creative Commons Non-commercial (CC-BY-NC) is a good place to start in terms of specifying who has access to your data.\n\n\n\n\n\n\nCautionExample 1: One recorder type, multiple recordings with the same settings\n\n\n\n\n\nAll recordings were made using the same type of recorder with identical acquisition settings (sampling rate, bit depth, etc.). Because the sampling rate and bit depth never change, those values are recorded once at the instrument level and inherited by each file. This avoids duplication while preserving clarity.\ntitle: \"Understory bird recordings (Panama)\"\ndescription: \"Autonomous recordings from fixed forest plots.\"\nlicense: \"CC-BY-4.0\"\n\ncreators:\n  - name: \"Patrick Kelley\"\n    orcid: \"0000-0002-1234-5678\"\n    affiliation: \"University of Wyoming\"\n\ninstruments:\n  - instrument_id: aru_01\n    type: \"Autonomous recording unit\"\n    manufacturer: \"Wildlife Acoustics\"\n    model: \"SM4\"\n    sampling_rate_hz: 48000\n    bit_depth: 24\n\nrecordings:\n  - file: \"plot1_2025-01-15_0600.wav\"\n    instrument_id: aru_01\n  - file: \"plot1_2025-01-15_0700.wav\"\n    instrument_id: aru_01\n  - file: \"plot1_2025-01-15_0800.wav\"\n    instrument_id: aru_01\n\n\n\n\n\n\n\n\n\nCautionExample 2: One recorder type, multiple recordings with different settings\n\n\n\n\n\nAlthough the same recorder model was used throughout, some recordings were made with different sampling rates. Because this parameter varies, it must be recorded explicitly for each file rather than summarized at the instrument-level.\ntitle: \"Understory bird recordings (Panama)\"\ndescription: \"Autonomous recordings; some files recorded at different sampling rates.\"\nlicense: \"CC-BY-4.0\"\n\ncreators:\n  - name: \"Patrick Kelley\"\n    orcid: \"0000-0002-1234-5678\"\n    affiliation: \"University of Wyoming\"\n\ninstruments:\n  - instrument_id: aru_01\n    type: \"Autonomous recording unit\"\n    manufacturer: \"Wildlife Acoustics\"\n    model: \"SM4\"\n    bit_depth: 24\n    default_sampling_rate_hz: 48000\n\nrecordings:\n  - file: \"plot1_2025-01-15_0600.wav\"\n    instrument_id: aru_01\n    sampling_rate_hz: 48000\n\n  - file: \"plot1_2025-01-15_0700.wav\"\n    instrument_id: aru_01\n    sampling_rate_hz: 48000\n\n  - file: \"plot1_2025-01-16_0600.wav\"\n    instrument_id: aru_01\n    sampling_rate_hz: 24000\n\n  - file: \"plot1_2025-01-16_0700.wav\"\n    instrument_id: aru_01\n    sampling_rate_hz: 24000\n\n\n\n\n\n\n\n\n\nCautionExample 3: Two recorder types, multiple recordings with the same settings\n\n\n\n\n\nTwo different recorder models were used, but each model operated with consistent settings across its recordings. Instrument-level metadata capture these stable differences, while individual files simply reference the appropriate instrument. This cleanly separates hardware differences from recording settings.\ntitle: \"Understory bird recordings (Panama)\"\ndescription: \"Recordings collected using two recorder models.\"\nlicense: \"CC-BY-4.0\"\n\ncreators:\n  - name: \"Patrick Kelley\"\n    orcid: \"0000-0002-1234-5678\"\n    affiliation: \"University of Wyoming\"\n\ninstruments:\n  - instrument_id: aru_01\n    type: \"Autonomous recording unit\"\n    manufacturer: \"Wildlife Acoustics\"\n    model: \"SM4\"\n    sampling_rate_hz: 48000\n    bit_depth: 24\n\n  - instrument_id: aru_02\n    type: \"Autonomous recording unit\"\n    manufacturer: \"Audiomoth\"\n    model: \"AudioMoth v1.2.0\"\n    sampling_rate_hz: 48000\n    bit_depth: 16\n\nrecordings:\n  - file: \"plot1_2025-01-15_0600.wav\"\n    instrument_id: aru_01\n  - file: \"plot1_2025-01-15_0700.wav\"\n    instrument_id: aru_01\n\n  - file: \"plot2_2025-01-15_0600.wav\"\n    instrument_id: aru_02\n  - file: \"plot2_2025-01-15_0700.wav\"\n    instrument_id: aru_02\n\n\n\n\n\n\n\n\n\nCautionExample 4: Two recorder types, multiple recordings with different settings\n\n\n\n\n\nBoth the recorder model and acquisition settings vary across recordings. In this case, instrument-level metadata define stable properties, while file-level metadata explicitly record variable settings such as sampling rate. This structure is necessary to fully document complexity without removing valuable variation.\ntitle: \"Understory bird recordings (Panama)\"\ndescription: \"Two recorder models with file-level variation in settings.\"\nlicense: \"CC-BY-4.0\"\n\ncreators:\n  - name: \"Patrick Kelley\"\n    orcid: \"0000-0002-1234-5678\"\n    affiliation: \"University of Wyoming\"\n\ninstruments:\n  - instrument_id: aru_01\n    type: \"Autonomous recording unit\"\n    manufacturer: \"Wildlife Acoustics\"\n    model: \"SM4\"\n    bit_depth: 24\n    default_sampling_rate_hz: 48000\n\n  - instrument_id: aru_02\n    type: \"Autonomous recording unit\"\n    manufacturer: \"Audiomoth\"\n    model: \"AudioMoth v1.2.0\"\n    bit_depth: 16\n    default_sampling_rate_hz: 48000\n\nrecordings:\n  - file: \"plot1_2025-01-15_0600.wav\"\n    instrument_id: aru_01\n    sampling_rate_hz: 48000\n\n  - file: \"plot1_2025-01-16_0600.wav\"\n    instrument_id: aru_01\n    sampling_rate_hz: 24000\n\n  - file: \"plot2_2025-01-15_0600.wav\"\n    instrument_id: aru_02\n    sampling_rate_hz: 48000\n\n  - file: \"plot2_2025-01-16_0600.wav\"\n    instrument_id: aru_02\n    sampling_rate_hz: 32000",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Metadata</span>"
    ]
  },
  {
    "objectID": "chapters/metadata_low_friction.html#wrapping-this-up",
    "href": "chapters/metadata_low_friction.html#wrapping-this-up",
    "title": "13  Metadata",
    "section": "13.11 Wrapping this up",
    "text": "13.11 Wrapping this up\nClear and clean metadata describe what your data are and how they were generated. Just as importantly, the names you give to files, variables, and folders determine whether that information remains interpretable as projects grow. In the next section, we turn to the topic of naming conventions and coding style –small and seemingly trivial decisions that play an outsized role in scientific reproducibility. Let’s proceed!",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Metadata</span>"
    ]
  },
  {
    "objectID": "chapters/naming_conventions.html",
    "href": "chapters/naming_conventions.html",
    "title": "14  Conventions and Style",
    "section": "",
    "text": "14.1 Why you should care (even if you “just want to model stuff”)\nNaming conventions and coding style are not decoration. They are infrastructure.\nIf your names are inconsistent, your code becomes harder to read, harder to debug, and harder to share—especially once your project grows beyond “one file, one afternoon.”\nIn scientific workflows, this difference is not about elegance. It is about traceability.\nA workflow that depends on unstable or unclear names cannot be audited, reused, or trusted.\nBefore we talk about modeling or automation, we need to ensure that the basic objects in our workflow—variables, files, and folders—are named in a way that makes their roles unambiguous.\nThis is what allows:",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Conventions and Style</span>"
    ]
  },
  {
    "objectID": "chapters/naming_conventions.html#why-you-should-care-even-if-you-just-want-to-model-stuff",
    "href": "chapters/naming_conventions.html#why-you-should-care-even-if-you-just-want-to-model-stuff",
    "title": "14  Conventions and Style",
    "section": "",
    "text": "“It’s the hardest job to come up with new and unique names for a variable every time you create one but this is the difference between an average programmer and a good one.”\n— Vikram Singh Rawat\n\n\n\n\n\n\n\n\n\nNoteThe three scientific costs of sloppy naming\n\n\n\n\nInteroperability cost:\nNon-standard names break workflows across tools, languages, and collaborators.\nCollaboration cost:\nInconsistent naming forces others (including Future You) to reverse-engineer intent.\nReproducibility cost:\nWhen names drift, inputs and outputs become ambiguous, and results can no longer be traced back to their sources.\n\n\n\n\n\n\nmetadata to point to the correct data,\nscripts to operate predictably,\nand workflows to declare dependencies explicitly.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Conventions and Style</span>"
    ]
  },
  {
    "objectID": "chapters/naming_conventions.html#naming-conventions-for-variables-and-files",
    "href": "chapters/naming_conventions.html#naming-conventions-for-variables-and-files",
    "title": "14  Conventions and Style",
    "section": "14.2 Naming conventions for variables and files",
    "text": "14.2 Naming conventions for variables and files\n\n\n\n14.2.1 What are “naming conventions”?\nThey are simply a consistent set of rules for naming:\n\nvariables (columns in your dataset)\nobjects in R (data frames, models, plots)\nfiles and folders (scripts, data, outputs)\n\n\n\n14.2.2 Three common naming styles\nYou will see these everywhere:\n\ncamelCase (meanDepth)\nPascalCase (MeanDepth)\nsnake_case (mean_depth)\n\nIn this course, we will default to snake_case for variables and files. This is strongly recommended for analysis scripts.\n\n\n\n\n\nFrom Allison Horst. Cartoon representations of common cases in coding. A snake screams “SCREAMING_SNAKE_CASE” into the face of a camel (wearing ear muffs) with “camelCase” written along its back. Vegetables on a skewer spell out “kebab-case” (words on a skewer). A mellow, happy looking snake has text “snake_case” along it.\n\n\n\n\n\n14.2.3 General guidelines (the “please don’t make future you angry” list)\nThese are simple rules that prevent a shocking number of problems:\n\n\n\n\n\n\n\n\n\nRule\nWhy it matters\nExample of poor form\n\n\n\n\nAvoid blank spaces\nSpaces complicate coding and break formulas, file paths, and scripting\nMean Depth, Site Name, Final Data.csv\n\n\nOmit special symbols like ?, $, *, +, #, (, ), -, /, }, {, |, &gt;, &lt;, etc.\nMany special characters are treated as operators or commands in R, so using them in names can break code or make it harder to work with.\nmass(g), count#, Y/N?, depth&gt;10\n\n\nUse _ as a separator\nUnderscores are safe, readable, and standard\nmean-depth, mean.depth, mean depth\n\n\nDo not begin names with numbers\nNames starting with numbers are invalid or confusing in R\n100m_depth, 2023_data\n\n\nMake names unique\nNon-unique names cause overwriting and ambiguity\ndata, data2, final, final_final\n\n\nBe consistent with case\nR is case-sensitive; inconsistency causes silent bugs\nDepth, depth, DEPTH in same project\n\n\nAvoid blank rows in data\nBlank rows can be misread as data or missing values\nEmpty rows between observations in CSV\n\n\nRemove comments from data files\nComments belong in scripts or metadata, not raw data\n# measured in June inside a CSV\n\n\nDefine and document NA values\nAmbiguous missing values lead to incorrect analyses\nMixing NA, 0, -999, . without explanation\n\n\nUse clear, documented date formats\nAmbiguous dates are easy to misinterpret\n03/04/21 (is this March 4 or April 3?)\n\n\n\n\n\n\n14.2.4 “Bad → Good” examples for variable names\nYour variable names should be: - readable at a glance - easy to type - consistent across files and projects\nHere are examples aligned with the tidyverse style guide (Hadley Wickham):\nA quick translation rule:\n\nUse units as suffixes: depth_cm, mass_g, distance_m (do not use parentheses around units)\nUse clear boolean names: yes_no or better: is_adult, has_nest\nPrefer meaning over brevity: percentile_50 beats p50 (unless p50 is a defined term in your field)",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Conventions and Style</span>"
    ]
  },
  {
    "objectID": "chapters/naming_conventions.html#naming-conventions-for-folders-project-structure",
    "href": "chapters/naming_conventions.html#naming-conventions-for-folders-project-structure",
    "title": "14  Conventions and Style",
    "section": "14.3 Naming conventions for folders (project structure)",
    "text": "14.3 Naming conventions for folders (project structure)\n\n14.3.1 Why folder names matter\nA good folder structure makes it hard to lose track of: - raw versus processed data - inputs versus outputs - code versus results - files that you can re-create versus ones you cannot (i.e. that you should never overwrite)\nIn this course, we care about reproducibility, which means: - raw data is always treated as read-only - processed data is created by scripts, acting on raw data, and never manually edited - results are generated by scripts and never manually edited\n\n\n\n\n\n\nTipA folder structure that scales\n\n\n\n\n\nA simple, stable structure (example):\n\ndata/\n\nraw_data/ (never edited)\nprocessed_data/ (created by scripts)\n\nr_scripts/ (functions + helpers)\nanalysis/ (analysis note / exercises )\noutputs/\n\nfigures/\ntables/\n\n\n\n\n\nFolder naming rules (same spirit as variable naming): - lowercase (snake_case) - no spaces - prefer underscores - descriptive names over clever names",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Conventions and Style</span>"
    ]
  },
  {
    "objectID": "chapters/naming_conventions.html#conventions-for-legible-and-consistent-r-code",
    "href": "chapters/naming_conventions.html#conventions-for-legible-and-consistent-r-code",
    "title": "14  Conventions and Style",
    "section": "14.4 Conventions for legible and consistent R code",
    "text": "14.4 Conventions for legible and consistent R code\n\n14.4.1 Why code style matters\nCode style is not about being fancy. It’s about making your thinking legible.\nGood style: - reduces bugs - improves peer review (including lab mates and future you) - makes it easier to modify models without breaking things\n\n\n\n\n\n\nNoteTwo extremely useful packages for checking R code formatting\n\n\n\n\nlintr checks your code for style problems (like a spellcheck for R code).\nstyler automatically formats your code to match a consistent style.\n\n\n\n\n\n14.4.2 “Bad → Good” examples for R code and files\nThese examples follow the tidyverse style guide (Hadley Wickham):\n\n\n\n\n\n\n\n\n\nBad\nWhy was it bad?\nGood\n\n\n\n\nFit models.r\nContains spaces; inconsistent casing; harder to reference in code\nfit_models.R\n\n\n##########\nNo semantic meaning; comments should describe intent, not fill space\n# extract elevation -----\n\n\nfindat\nVague name; gives no clue about content or structure\nfindat_mat\n\n\nfindat_mat\nRedundant and unclear; does not describe what the matrix contains\nmass_mat\n\n\n\n\nA few rules we will use repeatedly:\n\n\n14.4.3 Use nouns for objects and verbs for functions\n\nObjects (things): pufferi, pufferi_clean, model_gam\nFunctions (actions): clean_data(), fit_model(), plot_effects()\n\n\n\n14.4.4 Make “intermediate objects” obvious\nIf an object is temporary, label it like it is: - *_raw, *_clean, *_long, *_wide, *_summary\n\n\n14.4.5 Prefer readable code over clever code\n\n\n\n\n\n\n\n\nNoteOver-piped, confusing code\n\n\n\n\n\nsummary_df &lt;-\n  raw_df |&gt;\n  dplyr::filter(!is.na(count), year &gt;= 2015) |&gt;\n  dplyr::group_by(site, species) |&gt;\n  dplyr::summarise(\n    mean_count = mean(count),\n    sd_count   = sd(count),\n    n          = dplyr::n(),\n    .groups = \"drop\"\n  ) |&gt;\n  dplyr::filter(n &gt;= 5) |&gt;\n  dplyr::mutate(\n    cv = sd_count / mean_count,\n    log_mean = log(mean_count)\n  ) |&gt;\n  dplyr::arrange(dplyr::desc(log_mean))\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLonger but readable code\n\n\n\n\n\n# Step 1: keep valid observations from recent years\ndf_filtered &lt;- raw_df |&gt;\n  dplyr::filter(!is.na(count), year &gt;= 2015)\n\n# Step 2: summarize counts by site and species\ndf_summary &lt;- df_filtered |&gt;\n  dplyr::group_by(site, species) |&gt;\n  dplyr::summarise(\n    mean_count = mean(count),\n    sd_count   = sd(count),\n    n          = dplyr::n(),\n    .groups = \"drop\"\n  )\n\n# Step 3: retain well-sampled groups\ndf_sufficient &lt;- df_summary |&gt;\n  dplyr::filter(n &gt;= 5)\n\n# Step 4: compute derived metrics\ndf_metrics &lt;- df_sufficient |&gt;\n  dplyr::mutate(\n    cv       = sd_count / mean_count,\n    log_mean = log(mean_count)\n  )\n\n# Step 5: order results for inspection\nsummary_df &lt;- df_metrics |&gt;\n  dplyr::arrange(dplyr::desc(log_mean))\n\n\n\n\n\n\n\n14.4.6 A final note about reproducible analyses\nIn workflow tools like targets, names are not simply cosmetic. They define nodes in a dependency graph (i.e. the ways all your inputs, processes, and outputs are connected). If names are unclear, the graph is unclear. If the graph is unclear, the workflow is not reproducible.\n\n\n\n\n\n\nTipPractical guidance\n\n\n\n\nUse CSV/TSV when the dataset is small enough to load quickly and inspect easily.\nConsider .RDS when you want an R-native format that preserves object structure.\nConsider .parquet when files get big and you care about speed + file size.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Conventions and Style</span>"
    ]
  },
  {
    "objectID": "chapters/naming_conventions.html#your-minimum-standard-checklist-use-this-before-you-submit-anything",
    "href": "chapters/naming_conventions.html#your-minimum-standard-checklist-use-this-before-you-submit-anything",
    "title": "14  Conventions and Style",
    "section": "14.5 Your “minimum standard” checklist (use this before you submit anything)",
    "text": "14.5 Your “minimum standard” checklist (use this before you submit anything)\n\n\n\n\n\n\nNoteNaming + style checklist\n\n\n\nData + variables\n\nColumn names are snake_case\nNo spaces or special characters in column names\nUnits are explicit where relevant (_m, _cm, _g, _s)\nMissing values are documented (what is NA, what is 0, what is “not observed”?)\nDates are in a clear, documented format (and the order is not ambiguous)\n\nFolders + files\n\nFolder names are lowercase and descriptive\nRaw data are not edited in place\nProcessed data are created by scripts (not by hand)\n\nR code\n\nObjects use nouns; functions use verbs\nScripts are readable (spacing, line breaks, consistent naming)\nYou can restart R and run the workflow without relying on “things in memory”",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Conventions and Style</span>"
    ]
  },
  {
    "objectID": "chapters/naming_conventions.html#practice-task-recommended",
    "href": "chapters/naming_conventions.html#practice-task-recommended",
    "title": "14  Conventions and Style",
    "section": "14.6 Practice task (recommended)",
    "text": "14.6 Practice task (recommended)\n\nPick one of your current projects (or a past project).\nRename:\n\n5 confusing variables\n3 confusing files\n1 confusing folder\n\nMake one small style improvement:\n\nconsistent naming\nreadable comments\nbreak one long chunk into 2–3 meaningful steps\n\n\nThe goal is not perfection. The goal is to start practicing now.",
    "crumbs": [
      "Part I: Reproducible Analyses",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Conventions and Style</span>"
    ]
  }
]